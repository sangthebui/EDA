{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15291624",
   "metadata": {},
   "source": [
    "## Numpy Practice 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287425a",
   "metadata": {},
   "source": [
    "### Array creation\n",
    "- From https://numpy.org/doc/stable/user/basics.creation.html\n",
    "\n",
    "#### Introduction\n",
    "- There are 6 general mechanisms for creating arrays:\n",
    "\n",
    "    1. Conversion from other Python structures (i.e. lists and tuples)\n",
    "\n",
    "    2. Intrinsic NumPy array creation functions (e.g. arange, ones, zeros, etc.)\n",
    "\n",
    "    3. Replicating, joining, or mutating existing arrays\n",
    "\n",
    "    4. Reading arrays from disk, either from standard or custom formats\n",
    "\n",
    "    5. Creating arrays from raw bytes through the use of strings or buffers\n",
    "\n",
    "    6. Use of special library functions (e.g., random)\n",
    "\n",
    "- You can use these methods to create ndarrays or Structured arrays. This document will cover general methods for ndarray creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205c51e",
   "metadata": {},
   "source": [
    "### 1) Converting Python sequences to NumPy arrays\n",
    "- NumPy arrays can be defined using Python sequences such as lists and tuples. Lists and tuples are defined using [...] and (...), respectively. Lists and tuples can define ndarray creation:\n",
    "\n",
    "    - a list of numbers will create a 1D array,\n",
    "\n",
    "    - a list of lists will create a 2D array,\n",
    "\n",
    "    - further nested lists will create higher-dimensional arrays. In general, any array object is called an ndarray in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d69a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57d1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1D = np.array([1, 2, 3, 4])\n",
    "a2D = np.array([[1, 2], [3, 4]])\n",
    "a3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1d0e4",
   "metadata": {},
   "source": [
    "- When you use **numpy.array()** to define a new array, you should consider the dtype of the elements in the array, which can be specified explicitly. This feature gives you more control over the underlying data structures and how the elements are handled in C/C++ functions. When values do not fit and you are using a dtype, NumPy may raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636fe226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([127, 128, 129], dtype=np.int8) will cause over flow error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731cac6d",
   "metadata": {},
   "source": [
    "- An 8-bit signed integer represents integers from -128 to 127. Assigning the int8 array to integers outside of this range results in overflow. This feature can often be misunderstood. If you perform calculations with mismatching dtypes, you can get unwanted results, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d98329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsigned c: [4294967293 4294967293 4294967293] uint32\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2, 3, 4], dtype=np.uint32)\n",
    "b = np.array([5, 6, 7], dtype=np.uint32)\n",
    "c_unsigned32 = a - b\n",
    "print('unsigned c:', c_unsigned32, c_unsigned32.dtype) # cause overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f6f3e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signed c: [-3 -3 -3] int64\n"
     ]
    }
   ],
   "source": [
    "c_signed32 = a - b.astype(np.int32)\n",
    "print('signed c:', c_signed32, c_signed32.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306a716",
   "metadata": {},
   "source": [
    "- Notice when you perform operations with two arrays of the same dtype: uint32, the resulting array is the same type. When you perform operations with different dtype, NumPy will assign a new type that satisfies all of the array elements involved in the computation, here uint32 and int32 can both be represented in as int64.\n",
    "\n",
    "- The default NumPy behavior is to create arrays in either 32 or 64-bit signed integers (platform dependent and matches C long size) or double precision floating point numbers. If you expect your integer arrays to be a specific type, then you need to specify the dtype while you create the array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abbc86",
   "metadata": {},
   "source": [
    "#### 2) Intrinsic NumPy array creation functions\n",
    "- NumPy has over 40 built-in functions for creating arrays as laid out in the Array creation routines. These functions can be split into roughly three categories, based on the dimension of the array they create:\n",
    "    - 1D arrays\n",
    "    - 2D arrays\n",
    "    - ndarrays\n",
    "\n",
    "- 1 - 1D array creation functions\n",
    "The 1D array creation functions e.g. numpy.linspace and numpy.arange generally need at least two inputs, start and stop.\n",
    "\n",
    "- numpy.arange creates arrays with regularly incrementing values. Check the documentation for complete information and examples. A few examples are shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e302c164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a67b252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2, 10, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db221c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2, 3, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e806f",
   "metadata": {},
   "source": [
    "- Note: best practice for **numpy.arange** is to use integer start, end, and step values. There are some subtleties regarding dtype. In the second example, the dtype is defined. In the third example, the array is dtype=float to accommodate the step size of 0.1. Due to roundoff error, the stop value is sometimes included.\n",
    "\n",
    "- **numpy.linspace** will create arrays with a specified number of elements, and spaced equally between the specified beginning and end values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9089ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.6, 2.2, 2.8, 3.4, 4. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1., 4., 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0388b",
   "metadata": {},
   "source": [
    "- The advantage of this creation function is that you guarantee the number of elements and the starting and end point. The previous **arange(start, stop, step)** will not include the value stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560a479",
   "metadata": {},
   "source": [
    "### 2 - 2D array creation functions\n",
    "- The 2D array creation functions e.g. **numpy.eye**, **numpy.diag**, and **numpy.vander** define properties of special matrices represented as 2D arrays.\n",
    "\n",
    "- **np.eye(n, m)** defines a 2D identity matrix. The elements where i=j (row index and column index are equal) are 1 and the rest are 0, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f44f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b18759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f55c6d",
   "metadata": {},
   "source": [
    "- **numpy.diag** can define either a square 2D array with given values along the diagonal or if given a 2D array returns a 1D array that is only the diagonal elements. The two array creation functions can be helpful while doing linear algebra, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b981bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ffea04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 2, 0],\n",
       "       [0, 0, 0, 3],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag([1, 2, 3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c43dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "np.diag(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2d07c",
   "metadata": {},
   "source": [
    "- **vander(x, n)** defines a Vandermonde matrix as a 2D NumPy array. Each column of the Vandermonde matrix is a decreasing power of the input 1D array or list or tuple, x where the highest polynomial order is **n-1**. This array creation routine is helpful in generating linear least squares models, as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8168a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. ],\n",
       "       [0.5, 1. ],\n",
       "       [1. , 1. ],\n",
       "       [1.5, 1. ],\n",
       "       [2. , 1. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vander(np.linspace(0, 2, 5), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0166e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 1],\n",
       "       [3, 1],\n",
       "       [4, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vander([1, 2, 3, 4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aedff8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1],\n",
       "       [ 8,  4,  2,  1],\n",
       "       [27,  9,  3,  1],\n",
       "       [64, 16,  4,  1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vander((1, 2, 3, 4), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30642b4",
   "metadata": {},
   "source": [
    "#### 3 - general ndarray creation functions\n",
    "- The ndarray creation functions e.g. **numpy.ones**, **numpy.zeros**, and **random** define arrays based upon the desired shape. The ndarray creation functions can create arrays with any dimension by specifying how many dimensions and length along that dimension in a tuple or list.\n",
    "\n",
    "- **numpy.zeros** will create an array filled with 0 values with the specified shape. The default dtype is float64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08691ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc5928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]],\n",
       "\n",
       "       [[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06c638",
   "metadata": {},
   "source": [
    "- **numpy.ones** will create an array filled with 1 values. It is identical to zeros in all other respects as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97a69886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa9d3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((2, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579f689",
   "metadata": {},
   "source": [
    "- The **random** method of the result of default_rng will create an array filled with random values between 0 and 1. It is included with the **numpy.random** library. Below, two arrays are created with shapes (2,3) and (2,3,2), respectively. The seed is set to 42 so you can reproduce these pseudorandom numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620fbaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77395605, 0.43887844, 0.85859792],\n",
       "       [0.69736803, 0.09417735, 0.97562235]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "default_rng(42).random((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dac24bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.77395605, 0.43887844],\n",
       "        [0.85859792, 0.69736803],\n",
       "        [0.09417735, 0.97562235]],\n",
       "\n",
       "       [[0.7611397 , 0.78606431],\n",
       "        [0.12811363, 0.45038594],\n",
       "        [0.37079802, 0.92676499]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_rng(42).random((2, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ccad5",
   "metadata": {},
   "source": [
    "- **numpy.indices** will create a set of arrays (stacked as a one-higher dimensioned array), one per dimension with each representing variation in that dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d13cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2]],\n",
       "\n",
       "       [[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.indices((3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd94708",
   "metadata": {},
   "source": [
    "- This is particularly useful for evaluating functions of multiple dimensions on a regular grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2806b",
   "metadata": {},
   "source": [
    "#### 3) Replicating, joining, or mutating existing arrays\n",
    "- Once you have created arrays, you can replicate, join, or mutate those existing arrays to create new arrays. When you assign an array or its elements to a new variable, you have to explicitly **numpy.copy** the array, otherwise the variable is a view into the original array. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7506c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [2 3 3 4 5 6] ; b =  [2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5, 6])\n",
    "b = a[:2]\n",
    "b += 1\n",
    "print(\"a = \", a, \"; b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f0623",
   "metadata": {},
   "source": [
    "- In this example, you did not create a new array. You created a variable, b that viewed the first 2 elements of a. When you added 1 to b you would get the same result by adding 1 to a[:2]. If you want to create a new array, use the **numpy.copy** array creation routine as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a5e3343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [1 2 3 4] ; b =  [2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = a[:2].copy()\n",
    "b += 1\n",
    "print(\"a = \", a, \"; b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095edbf8",
   "metadata": {},
   "source": [
    "- There are a number of routines to join existing arrays e.g. **numpy.vstack**, **numpy.hstack**, and **numpy.block**. Here is an example of joining four 2-by-2 arrays into a 4-by-4 array using block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e078ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  1.],\n",
       "       [ 0.,  0., -3.,  0.],\n",
       "       [ 0.,  0.,  0., -4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.ones((2, 2))\n",
    "B = np.eye(2, 2) # eye accepts comma separated values instead of a tuple of shape, Weird\n",
    "C = np.zeros((2, 2))\n",
    "D = np.diag((-3, -4))\n",
    "np.block([[A, B], [C, D]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de04bce",
   "metadata": {},
   "source": [
    "- Other routines use similar syntax to join ndarrays. Check the routine’s documentation for further examples and syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b9711",
   "metadata": {},
   "source": [
    "#### 4) Reading arrays from disk, either from standard or custom formats\n",
    "- This is the most common case of large array creation. The details depend greatly on the format of data on disk. This section gives general pointers on how to handle various formats. For more detailed examples of IO look at How to Read and Write files.\n",
    "\n",
    "#### Standard binary formats\n",
    "- Various fields have standard formats for array data. The following lists the ones with known Python libraries to read them and return NumPy arrays (there may be others for which it is possible to read and convert to NumPy arrays so check the last section as well)\n",
    "- Examples of formats that cannot be read directly but for which it is not hard to convert are those formats supported by libraries like PIL (able to read and write many image formats such as jpg, png, etc).\n",
    "\n",
    "#### Common ASCII formats\n",
    "- Delimited files such as comma separated value (csv) and tab separated value (tsv) files are used for programs like Excel and LabView. Python functions can read and parse these files line-by-line. NumPy has two standard routines for importing a file with delimited data **numpy.loadtxt** and **numpy.genfromtxt**. These functions have more involved use cases in Reading and writing files. A simple example given a simple.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9df305d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thotc\\AppData\\Local\\Temp\\ipykernel_52308\\4239721289.py:1: UserWarning: loadtxt: input contained no data: \"data/simple.csv\"\n",
      "  np.loadtxt(\"data/simple.csv\", delimiter=\",\", skiprows = 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(\"data/simple.csv\", delimiter=\",\", skiprows = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e42b4f",
   "metadata": {},
   "source": [
    "#### 5) Creating arrays from raw bytes through the use of strings or buffers\n",
    "- There are a variety of approaches one can use. If the file has a relatively simple format then one can write a simple I/O library and use the NumPy fromfile() function and .tofile() method to read and write NumPy arrays directly (mind your byteorder though!) If a good C or C++ library exists that read the data, one can wrap that library with a variety of techniques though that certainly is much more work and requires significantly more advanced knowledge to interface with C or C++."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b9fcf",
   "metadata": {},
   "source": [
    "#### 6) Use of special library functions (e.g., SciPy, pandas, and OpenCV)\n",
    "- NumPy is the fundamental library for array containers in the Python Scientific Computing stack. Many Python libraries, including SciPy, Pandas, and OpenCV, use NumPy ndarrays as the common format for data exchange, These libraries can create, operate on, and work with NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fa832",
   "metadata": {},
   "source": [
    "### Indexing on ndarrays\n",
    "- From https://numpy.org/doc/stable/user/basics.indexing.html\n",
    "- ndarrays can be indexed using the standard Python x[obj] syntax, where x is the array and obj the selection. There are different kinds of indixing available depending on obj: basic indexing, advanced indexing and field access.\n",
    "- Most of the following examples show the use of indexing when referencing data in an array. The examples work just as well when assigning to an array. \n",
    "- Note that in Python, x[(exp1, exp2, ..., expN)] is equivalent to x[exp1, exp2, ..., expN]; the latter is just syntatic sugar for the former.\n",
    "\n",
    "#### Basic indexing\n",
    "#### Single element indexing\n",
    "- Single element indexing works exactly like that for other standard Python sequences. It is 0-based, and accepts negative indices for indexing from the end of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78852a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ec9f68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e500de8",
   "metadata": {},
   "source": [
    "- It is not necessary to separate each dimension's index into its own set of square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5078bbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape = (2, 5) # now is a 2-dimensional\n",
    "x[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8452129a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d356f2d",
   "metadata": {},
   "source": [
    "- Note that if one indexes a multidimensional array with fewer indices than dimensions, one gets a subdimensional array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afdcb548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35500f0e",
   "metadata": {},
   "source": [
    "- That is, each index specified selects the array corresponding to the rest of the dimensions selected. In the above example, choosing 0 means that the remaining dimension of length 5 is being left unspecified, and that what is returned is an array of that dimensionality and size. It must be noted that the returned array is a view, i.e., it is not a copy of the original, but points to the same values in memory as does the original array. In this case, the 1-D array at the first position (0) is returned. So using a single index on the returned array, results in a single element being returned. That is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1afa9ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755fca0d",
   "metadata": {},
   "source": [
    "- So note that x[0, 2] == x[0][2] though the second case is more inefficient as a new temporary array is created after the first index that is subsequently indexed by 2.\n",
    "- **Note**: NumPy uses C-order indexing. That means that the last index usually represents the most rapidly changing memory location, unlike Fortran or IDL, where the first index represents the most rapidly changing location in memory. This difference represents a great potential for confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899a49f",
   "metadata": {},
   "source": [
    "#### Slicing and striding\n",
    "- Basic slicing extends Python’s basic concept of slicing to N dimensions. Basic slicing occurs when obj is a **slice** object (constructed by **start:stop:step** notation inside of brackets), an integer, or a tuple of slice objects and integers. **Ellipsis** and **newaxis** objects can be interspersed with these as well.\n",
    "\n",
    "- The simplest case of indexing with N integers returns an array scalar representing the corresponding item. As in Python, all indices are zero-based: for the i-th index \n",
    ", the valid range is \n",
    " where \n",
    " is the i-th element of the shape of the array. Negative indices are interpreted as counting from the end of the array (i.e., if \n",
    ", it means \n",
    ").\n",
    "\n",
    "- All arrays generated by basic slicing are always views of the original array.\n",
    "- **Note**: NumPy slicing creates a view instead of a copy as in the case of built-in Python sequences such as string, tuple and list. Care must be taken when extracting a small portion from a large array which becomes useless after the extraction, because the small portion extracted contains a reference to the large original array whose memory will not be released until all arrays derived from it are garbage-collected. In such cases an explicit **copy()** is recommended.\n",
    "- The standard rules of sequence slicing apply to basic slicing on a per-dimension basis (including using a step index). Some useful concepts to remember include:\n",
    "\n",
    "- The basic slice syntax is i:j:k where i is the starting index, j is the stopping index, and k is the step **(k !=0)**\n",
    "). This selects the m elements (in the corresponding dimension) with index values i, i + k, …, i + (m - 1) k where **m = q + (r != 0)**\n",
    " and q and r are the quotient and remainder obtained by dividing j - i by k: j - i = q k + r, so that i + (m - 1) k < j. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d5faa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "x[1:7:2] # start at 2, ends at 7, select every 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ccc7d",
   "metadata": {},
   "source": [
    "- Negative i and j are interpreted as n + i and n + j where n is the number of elements in the corresponding dimension. Negative k makes stepping go towards smaller indices. From the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23163982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-2:10] # starts at -2 (or len - 2), ends at 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9834832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 5, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-3:3:-1] # starts at -3, ends at 3, go backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb83e1",
   "metadata": {},
   "source": [
    "- Assume n is the number of elements in the dimension being sliced. Then, if i is not given it defaults to 0 for k > 0 and n - 1 for k < 0 . If j is not given it defaults to n for k > 0 and -n-1 for k < 0 . If k is not given it defaults to 1. Note that :: is the same as : and means select all indices along this axis. From the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bbbba51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e447886",
   "metadata": {},
   "source": [
    "- If the number of objects in the selection tuple is less than N, then : is assumed for any subsequent dimensions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03dd8c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[1], [2], [3]], [[4], [5], [6]]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21b224e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4],\n",
       "        [5],\n",
       "        [6]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec63b2",
   "metadata": {},
   "source": [
    "- An integer, i, returns the same values as i:i+1 except the dimensionality of the returned object is reduced by 1. In particular, a selection tuple with the p-th element an integer (and all other entries :) returns the corresponding sub-array with dimension N - 1. If N = 1 then the returned object is an array scalar. These objects are explained in Scalars.\n",
    "\n",
    "- If the selection tuple has all entries : except the p-th entry which is a slice object i:j:k, then the returned array has dimension N formed by stacking, along the p-th axis, the sub-arrays returned by integer indexing of elements i, i+k, …, i + (m - 1) k < j.\n",
    "\n",
    "- Basic slicing with more than one non-: entry in the slicing tuple, acts like repeated application of slicing using a single non-: entry, where the non-: entries are successively taken (with all other non-: entries replaced by :). Thus, x[ind1, ..., ind2,:] acts like x[ind1][..., ind2, :] under basic slicing.\n",
    "\n",
    "- **Warning**: The above is not true for advanced indexing.\n",
    "\n",
    "- You may use slicing to set values in the array, but (unlike lists) you can never grow the array. The size of the value to be set in x[obj] = value must be (broadcastable to) the same shape as x[obj].\n",
    "\n",
    "- A slicing tuple can always be constructed as obj and used in the x[obj] notation. Slice objects can be used in the construction in place of the [start:stop:step] notation. For example, x[1:10:5, ::-1] can also be implemented as obj = (slice(1, 10, 5), slice(None, None, -1)); x[obj] . This can be useful for constructing generic code that works on arrays of arbitrary dimensions. See Dealing with variable numbers of indices within programs for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e899c89",
   "metadata": {},
   "source": [
    "#### Dimensional indexing tools\n",
    "- There are some tools to facilitate the easy matching of array shapes with expressions and in assignments.\n",
    "\n",
    "- Ellipsis expands to the number of : objects needed for the selection tuple to index all dimensions. In most cases, this means that the length of the expanded selection tuple is x.ndim. There may only be a single ellipsis present. From the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "810d63ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[..., 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fd23c",
   "metadata": {},
   "source": [
    "- This is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "319a5d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f8a74",
   "metadata": {},
   "source": [
    "- Each **newaxis** object in the selection tuple serves to expand the dimensions of the resulting selection by one unit-length dimension. The added dimension is the position of the **newaxis** object in the selection tuple. **newaxis** is an alias for None, and None can be used in place of this with the same result. From the above example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32a52657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, np.newaxis, :, :].shape # Use the newaxis to create a new column (aka a new dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e08a5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, None, :, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62164058",
   "metadata": {},
   "source": [
    "- This can be handy to combine two arrays in a way that otherwise would require explicit reshaping operations. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "863a7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbc1abd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [2, 3, 4, 5, 6],\n",
       "       [3, 4, 5, 6, 7],\n",
       "       [4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, np.newaxis] + x[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f9cccc",
   "metadata": {},
   "source": [
    "#### Advanced indexing\n",
    "- Advanced indexing is triggered when the selection object, obj, is a non-tuple sequence object, an **ndarray** (of data type integer or bool), or a tuple with at least one sequence object or ndarray (of data type integer or bool). There are two types of advanced indexing: integer and Boolean.\n",
    "- Advanced indexing always returns a copy of the data (contrast with basic slicing that returns a view).\n",
    "- **Warning**: The definition of advanced indexing means that x[(1, 2, 3),] is fundamentally different than x[(1, 2, 3)]. The latter is equivalent to x[1, 2, 3] which will trigger basic selection while the former will trigger advanced indexing. Be sure to understand why this occurs.\n",
    "\n",
    "#### Integer array indexing\n",
    "- Integer array indexing allows selection of arbitrary items in the array based on their N-dimensional index. Each integer array represents a number of indices into that dimension.\n",
    "- Negative values are permitted in the index arrays and work as they do with single indices or slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a493aa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  8,  7,  6,  5,  4,  3,  2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10, 1, -1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d1cf41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 9, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.array([3, 3, 1, 8])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f3ee5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 4, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.array([3, 3, -3, 8])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4250c",
   "metadata": {},
   "source": [
    "- If the index values are out of bounds then an IndexError is thrown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd68ea63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "x[np.array([1, -1])]\n",
    "# x[np.array([3, 4])] # will throw an IndexError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ea0e2",
   "metadata": {},
   "source": [
    "- When the index consists of as many integer arrays as dimensions of the array being indexed, the indexing is straightforward, but different from slicing.\n",
    "\n",
    "- Advanced indices always are **broadcast** and iterated as one:\n",
    "- Note that the resulting shape is identical to the (broadcast) indexing array shapes ind_1, ..., ind_N. If the indices cannot be broadcast to the same shape, an exception IndexError: shape mismatch: indexing arrays could not be broadcast together with shapes... is raised.\n",
    "\n",
    "- Indexing with multidimensional index arrays tend to be more unusual uses, but they are permitted, and they are useful for some problems. We’ll start with the simplest multidimensional case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19e737f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12, 13],\n",
       "       [14, 15, 16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25, 26, 27],\n",
       "       [28, 29, 30, 31, 32, 33, 34]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(35).reshape(5, 7)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c271679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 15, 30])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.array([0, 2, 4]), np.array([0, 1, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09abd71c",
   "metadata": {},
   "source": [
    "- In this case, if the index arrays have a matching shape, and there is an index array for each dimension of the array being indexed, the resultant array has the same shape as the index arrays, and the values correspond to the index set for each position in the index arrays. In this example, the first index value is 0 for both index arrays, and thus the first value of the resultant array is y[0, 0]. The next value is y[2, 1], and the last is y[4, 2].\n",
    "\n",
    "If the index arrays do not have the same shape, there is an attempt to broadcast them to the same shape. If they cannot be broadcast to the same shape, an exception is raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b3db930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[np.array([0, 2, 4]), np.array([0, 1])] # will produce an IndexError: shape mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da81e39",
   "metadata": {},
   "source": [
    "- The broadcasting mechanism permits index arrays to be combined with scalars for other indices. The effect is that the scalar value is used for all the corresponding values of the index arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7af7838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 15, 29])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.array([0, 2, 4]), 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c5966",
   "metadata": {},
   "source": [
    "- Jumping to the next level of complexity, it is possible to only partially index an array with index arrays. It takes a bit of thought to understand what happens in such cases. For example if we just use one index array with y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d88b981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
       "       [14, 15, 16, 17, 18, 19, 20],\n",
       "       [28, 29, 30, 31, 32, 33, 34]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.array([0, 2, 4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848b15ce",
   "metadata": {},
   "source": [
    "- It results in the construction of a new array where each value of the index array selects one row from the array being indexed and the resultant array has the resulting shape (number of index elements, size of row).\n",
    "\n",
    "- In general, the shape of the resultant array will be the concatenation of the shape of the index array (or the shape that all the index arrays were broadcast to) with the shape of any unused dimensions (those not indexed) in the array being indexed.\n",
    "\n",
    "#### Example\n",
    "- From each row, a specific element should be selected. The row index is just [0, 1, 2] and the column index specifies the element to choose for the corresponding row, here [0, 1, 0]. Using both together the task can be solved using advanced indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48e5076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "x[[0, 1, 2], [0, 1, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b834bee4",
   "metadata": {},
   "source": [
    "- To achieve a behaviour similar to the basic slicing above, broadcasting can be used. The function ix_ can help with this broadcasting. This is best understood with an example.\n",
    "\n",
    "#### Example\n",
    "- From a 4x3 array the corner elements should be selected using advanced indexing. Thus all elements for which the column is one of [0, 2] and the row is one of [0, 3] need to be selected. To use advanced indexing one needs to select all elements explicitly. Using the method explained previously one could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2a34890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[ 0,  1,  2],\n",
    "              [ 3,  4,  5],\n",
    "              [ 6,  7,  8],\n",
    "              [ 9, 10, 11]])\n",
    "\n",
    "rows = np.array([[0, 0],\n",
    "                 [3, 3]], dtype=np.intp) \n",
    "columns = np.array([[0, 2],\n",
    "                    [0, 2]], dtype=np.intp)\n",
    "x[rows, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e45d2",
   "metadata": {},
   "source": [
    "- However, since the indexing arrays above just repeat themselves, broadcasting can be used (compare operations such as rows[:, np.newaxis] + columns) to simplify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d9974b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = np.array([0, 3], dtype=np.intp)\n",
    "columns = np.array([0, 2], dtype=np.intp)\n",
    "rows[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6da216f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[rows[:, np.newaxis], columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963bd8b",
   "metadata": {},
   "source": [
    "- This broadcasting can also be achieved using the function ix_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60c45fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.ix_(rows, columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a102c8",
   "metadata": {},
   "source": [
    "- Note that without the np.ix_ call, only the diagonal elements would be selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf740efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[rows, columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb8b8e",
   "metadata": {},
   "source": [
    "- This difference is the most important thing to remember about indexing with multiple advanced indices.\n",
    "\n",
    "#### Example\n",
    "- A real-life example of where advanced indexing may be useful is for a color lookup table where we want to map the values of an image into RGB triples for display. The lookup table could have a shape (nlookup, 3). Indexing such an array with an image with shape (ny, nx) with dtype=np.uint8 (or any integer type so long as values are with the bounds of the lookup table) will result in an array of shape (ny, nx, 3) where a triple of RGB values is associated with each pixel location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4570c",
   "metadata": {},
   "source": [
    "#### Boolean array indexing\n",
    "- This advanced indexing occurs when obj is an array object of Boolean type, such as may be returned from comparison operators. A single boolean index array is practically identical to **x[obj.nonzero()]** where, as described above, **obj.nonzero()** returns a tuple (of length **obj.ndim**) of integer index arrays showing the True elements of obj. However, it is faster when **obj.shape == x.shape**.\n",
    "\n",
    "- If **obj.ndim == x.ndim**, **x[obj]** returns a 1-dimensional array filled with the elements of x corresponding to the True values of obj. The search order will be row-major, C-style. An index error will be raised if the shape of obj does not match the corresponding dimensions of x, regardless of whether those values are True or False.\n",
    "\n",
    "- A common use case for this is filtering for desired element values. For example, one may wish to select all entries from an array which are not numpy.nan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71ec9653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1., 2.], [np.nan, 3.], [np.nan, np.nan]])\n",
    "x[~np.isnan(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3d5e4",
   "metadata": {},
   "source": [
    "- Or wish to add a constant to all negative elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b8b8689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 19., 18.,  3.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., -1., -2., 3])\n",
    "x[x < 0] += 20 # any indices less than 0, add 20 to it\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edf574",
   "metadata": {},
   "source": [
    "- In general if an index includes a Boolean array, the result will be identical to inserting obj.nonzero() into the same position and using the integer array indexing mechanism described above. x[ind_1, boolean_array, ind_2] is equivalent to x[(ind_1,) + boolean_array.nonzero() + (ind_2,)].\n",
    "\n",
    "- If there is only one Boolean array and no integer indexing array present, this is straightforward. Care must only be taken to make sure that the boolean index has exactly as many dimensions as it is supposed to work with.\n",
    "\n",
    "- In general, when the boolean array has fewer dimensions than the array being indexed, this is equivalent to x[b, ...], which means x is indexed by b followed by as many : as are needed to fill out the rank of x. Thus the shape of the result is one dimension containing the number of True elements of the boolean array, followed by the remaining dimensions of the array being indexed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28cd01d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(35).reshape(5, 7)\n",
    "b = x > 20\n",
    "b[:, 5] # create a boolean indices take all the column, and the column index 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a47a31dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 22, 23, 24, 25, 26, 27],\n",
       "       [28, 29, 30, 31, 32, 33, 34]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[b[:, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b739a4",
   "metadata": {},
   "source": [
    "- Here the 4th and 5th rows are selected from the indexed array and combined to make a 2-D array.\n",
    "\n",
    "#### Example\n",
    "- From an array, select all rows which sum up to less or equal two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3a7f36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0, 1], [1, 1], [2, 2]])\n",
    "rowsum = x.sum(-1)\n",
    "x[rowsum <= 2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741a09a",
   "metadata": {},
   "source": [
    "- Combining multiple Boolean indexing arrays or a Boolean with an integer indexing array can best be understood with the **obj.nonzero()** analogy. The function **ix_** also supports boolean arrays and will work without any surprises.\n",
    "#### Example\n",
    "- Use boolean indexing to select all rows adding up to an even number. At the same time columns 0 and 2 should be selected with an advanced integer index. Using the **ix_** function this can be done with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1040fb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[ 0,  1,  2],\n",
    "              [ 3,  4,  5],\n",
    "              [ 6,  7,  8],\n",
    "              [ 9, 10, 11]])\n",
    "rows = (x.sum(-1) % 2) == 0 # create an array of the sums of  each row, then get the even of those sums\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b93015f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  5],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [0, 2]\n",
    "x[np.ix_(rows, columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154a1a3",
   "metadata": {},
   "source": [
    "- Without the **np.ix_** call, only the diagonal elements would be selected.\n",
    "\n",
    "- Or without **np.ix_** (compare the integer array examples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6968a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  5],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = rows.nonzero()[0]\n",
    "x[rows[:, np.newaxis], columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e44ab",
   "metadata": {},
   "source": [
    "#### Example\n",
    "- Use a 2-D boolean array of shape (2, 3) with four True elements to select rows from a 3-D array of shape (2, 3, 5) results in a 2-D result of shape (4, 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5fe8b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14]],\n",
       "\n",
       "       [[15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(30).reshape(2, 3, 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03c6770d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [20, 21, 22, 23, 24],\n",
       "       [25, 26, 27, 28, 29]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[True, True, False], [False, True, True]])\n",
    "x[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfcc5d",
   "metadata": {},
   "source": [
    "#### Combining advanced and basic indexing\n",
    "- When there is at least one slice (:), ellipsis (...) or newaxis in the index (or the array has more dimensions than there are advanced indices), then the behaviour can be more complicated. It is like concatenating the indexing result for each advanced index element.\n",
    "\n",
    "- In the simplest case, there is only a single advanced index combined with a slice. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8580b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [15, 16],\n",
       "       [29, 30]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(35).reshape(5,7)\n",
    "y[np.array([0, 2, 4]), 1:3] # take the 0, 2, 4 row, and the 1, 2 column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c751237",
   "metadata": {},
   "source": [
    "- In effect, the slice and index array operation are independent. The slice operation extracts columns with index 1 and 2, (i.e. the 2nd and 3rd columns), followed by the index array operation which extracts rows with index 0, 2 and 4 (i.e the first, third and fifth rows). This is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0341027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [15, 16],\n",
       "       [29, 30]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 1:3][np.array([0, 2, 4]), :] # could also break it up into 2 look up via bracket []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838be609",
   "metadata": {},
   "source": [
    "- A single advanced index can, for example, replace a slice and the result array will be the same. However, it is a copy and may have a different memory layout. A slice is preferable when it is possible. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c923354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[ 0,  1,  2],\n",
    "              [ 3,  4,  5],\n",
    "              [ 6,  7,  8],\n",
    "              [ 9, 10, 11]])\n",
    "x[1:2, 1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eaf1a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1:2, [1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f676d",
   "metadata": {},
   "source": [
    "- The easiest way to understand a combination of multiple advanced indices may be to think in terms of the resulting shape. There are two parts to the indexing operation, the subspace defined by the basic indexing (excluding integers) and the subspace from the advanced indexing part. Two cases of index combination need to be distinguished:\n",
    "    - The advanced indices are separated by a slice, Ellipsis or newaxis. For example x[arr1, :, arr2].\n",
    "    - The advanced indices are all next to each other. For example x[..., arr1, arr2, :] but not x[arr1, :, 1] since 1 is an advanced index in this regard.\n",
    "\n",
    "- In the first case, the dimensions resulting from the advanced indexing operation come first in the result array, and the subspace dimensions after that. In the second case, the dimensions from the advanced indexing operations are inserted into the result array at the same spot as they were in the initial array (the latter logic is what makes simple advanced indexing behave just like slicing).\n",
    "#### Example\n",
    "- Suppose x.shape is (10, 20, 30) and ind is a (2, 5, 2)-shaped indexing intp array, then result = x[..., ind, :] has shape (10, 2, 5, 2, 30) because the (20,)-shaped subspace has been replaced with a (2, 5, 2)-shaped broadcasted indexing subspace. If we let i, j, k loop over the (2, 5, 2)-shaped subspace then result[..., i, j, k, :] = x[..., ind[i, j, k], :]. This example produces the same result as x.take(ind, axis=-2).\n",
    "\n",
    "#### Example\n",
    "- Let x.shape be (10, 20, 30, 40, 50) and suppose ind_1 and ind_2 can be broadcast to the shape (2, 3, 4). Then x[:, ind_1, ind_2] has shape (10, 2, 3, 4, 40, 50) because the (20, 30)-shaped subspace from X has been replaced with the (2, 3, 4) subspace from the indices. However, x[:, ind_1, :, ind_2] has shape (2, 3, 4, 10, 30, 50) because there is no unambiguous place to drop in the indexing subspace, thus it is tacked-on to the beginning. It is always possible to use .transpose() to move the subspace anywhere desired. Note that this example cannot be replicated using take.\n",
    "#### Example\n",
    "- Slicing can be combined with broadcasted boolean indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2622b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [False, False, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(35).reshape(5, 7)\n",
    "b = x > 20\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "386d2322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, 23],\n",
       "       [29, 30]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[b[:, 5], 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bd53",
   "metadata": {},
   "source": [
    "#### Field access\n",
    "- If the ndarray object is a structured array the fields of the array can be accessed by indexing the array with strings, dictionary-like.\n",
    "- Indexing x['field-name'] returns a new view to the array, which is of the same shape as x (except when the field is a sub-array) but of data type x.dtype['field-name'] and contains only the part of the data in the specified field. Also, record array scalars can be “indexed” this way.\n",
    "- Indexing into a structured array can also be done with a list of field names, e.g. x[['field-name1', 'field-name2']]. As of NumPy 1.16, this returns a view containing only those fields. In older versions of NumPy, it returned a copy. See the user guide section on Structured arrays for more information on multifield indexing.\n",
    "- If the accessed field is a sub-array, the dimensions of the sub-array are appended to the shape of the result. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06a05f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\n",
    "x['a'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb1b3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['a'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb183c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00847536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['b'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742f3a3d",
   "metadata": {},
   "source": [
    "#### Flat iterator indexing\n",
    "- x.flat returns an iterator that will iterate over the entire array (in C-contiguous style with the last index varying the fastest). This iterator object can also be indexed using basic slicing or advanced indexing as long as the selection object is not a tuple. This should be clear from the fact that x.flat is a 1-dimensional view. It can be used for integer indexing with 1-dimensional C-style-flat indices. The shape of any returned array is therefore the shape of the integer indexing object.\n",
    "\n",
    "#### Assigning values to indexed arrays\n",
    "- As mentioned, one can select a subset of an array to assign to using a single index, slices, and index and mask arrays. The value being assigned to the indexed array must be shape consistent (the same shape or broadcastable to the shape the index produces). For example, it is permitted to assign a constant to a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4a68910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 7, 8, 9])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x[2:7] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39293a9",
   "metadata": {},
   "source": [
    "- or an array of the right size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "518f3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 2, 3, 4, 7, 8, 9])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:7] = np.arange(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a07d5",
   "metadata": {},
   "source": [
    "- Note that assignments may result in changes if assigning higher types to lower types (like floats to ints) or even exceptions (assigning complex to floats or ints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1266cbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1] = 1.2\n",
    "x[1]\n",
    "# x[1] = 1.2j  will cause a TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff7a3be",
   "metadata": {},
   "source": [
    "- Unlike some of the references (such as array and mask indices) assignments are always made to the original data in the array (indeed, nothing else would make sense!). Note though, that some actions may not work as one may naively expect. This particular example is often surprising to people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2cafc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 20, 30, 40])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(0, 50, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f060ec14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 11, 20, 31, 40])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[np.array([1, 1, 3, 1])] += 1 # select the indices to increment by 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7dcd80",
   "metadata": {},
   "source": [
    "- Where people expect that the 1st location will be incremented by 3. In fact, it will only be incremented by 1. The reason is that a new array is extracted from the original (as a temporary) containing the values at 1, 1, 3, 1, then the value 1 is added to the temporary, and then the temporary is assigned back to the original array. Thus the value of the array at x[1] + 1 is assigned to x[1] three times, rather than being incremented 3 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57696ae",
   "metadata": {},
   "source": [
    "#### Dealing with variable numbers of indices within programs\n",
    "- The indexing syntax is very powerful but limiting when dealing with a variable number of indices. For example, if you want to write a function that can handle arguments with various numbers of dimensions without having to write special case code for each number of possible dimensions, how can that be done? If one supplies to the index a tuple, the tuple will be interpreted as a list of indices. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "78782158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(40)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.arange(81).reshape(3, 3, 3, 3)\n",
    "indices = (1, 1, 1, 1)\n",
    "z[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e1e2c",
   "metadata": {},
   "source": [
    "- So one can use code to construct tuples of any number of indices and then use these within an index.\n",
    "- Slices can be specified within programs by using the slice() function in Python. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a4c38351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 40])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = (1, 1, 1, slice(0, 2))  # same as [1, 1, 1, 0:2]\n",
    "z[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b42b31b",
   "metadata": {},
   "source": [
    "- Likewise, ellipsis can be specified by code by using the Ellipsis object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ede03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 31, 34],\n",
       "       [37, 40, 43],\n",
       "       [46, 49, 52]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = (1, Ellipsis, 1)  # same as [1, ..., 1]\n",
    "z[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c7b8d",
   "metadata": {},
   "source": [
    "- For this reason, it is possible to use the output from the np.nonzero() function directly as an index since it always returns a tuple of index arrays.\n",
    "- Because of the special treatment of tuples, they are not automatically converted to an array as a list would be. As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a84172b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44]],\n",
       "\n",
       "        [[45, 46, 47],\n",
       "         [48, 49, 50],\n",
       "         [51, 52, 53]]],\n",
       "\n",
       "\n",
       "       [[[27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44]],\n",
       "\n",
       "        [[45, 46, 47],\n",
       "         [48, 49, 50],\n",
       "         [51, 52, 53]]],\n",
       "\n",
       "\n",
       "       [[[27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44]],\n",
       "\n",
       "        [[45, 46, 47],\n",
       "         [48, 49, 50],\n",
       "         [51, 52, 53]]],\n",
       "\n",
       "\n",
       "       [[[27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]],\n",
       "\n",
       "        [[36, 37, 38],\n",
       "         [39, 40, 41],\n",
       "         [42, 43, 44]],\n",
       "\n",
       "        [[45, 46, 47],\n",
       "         [48, 49, 50],\n",
       "         [51, 52, 53]]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[[1, 1, 1, 1]]  # produces a large array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2d2d706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(40)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[(1, 1, 1, 1)]  # returns a single value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7386273d",
   "metadata": {},
   "source": [
    "#### Detailed notes\n",
    "- These are some detailed notes, which are not of importance for day to day indexing (in no particular order):\n",
    "\n",
    "- The native NumPy indexing type is intp and may differ from the default integer array type. intp is the smallest data type sufficient to safely index any array; for advanced indexing it may be faster than other types.\n",
    "\n",
    "- For advanced assignments, there is in general no guarantee for the iteration order. This means that if an element is set more than once, it is not possible to predict the final result.\n",
    "\n",
    "- An empty (tuple) index is a full scalar index into a zero-dimensional array. x[()] returns a scalar if x is zero-dimensional and a view otherwise. On the other hand, x[...] always returns a view.\n",
    "\n",
    "- If a zero-dimensional array is present in the index and it is a full integer index the result will be a scalar and not a zero-dimensional array. (Advanced indexing is not triggered.)\n",
    "\n",
    "- When an ellipsis (...) is present but has no size (i.e. replaces zero :) the result will still always be an array. A view if no advanced index is present, otherwise a copy.\n",
    "\n",
    "- The nonzero equivalence for Boolean arrays does not hold for zero dimensional boolean arrays.\n",
    "\n",
    "- When the result of an advanced indexing operation has no elements but an individual index is out of bounds, whether or not an IndexError is raised is undefined (e.g. x[[], [123]] with 123 being out of bounds).\n",
    "\n",
    "- When a casting error occurs during assignment (for example updating a numerical array using a sequence of strings), the array being assigned to may end up in an unpredictable partially updated state. However, if any other error (such as an out of bounds index) occurs, the array will remain unchanged.\n",
    "\n",
    "- The memory layout of an advanced indexing result is optimized for each indexing operation and no particular memory order can be assumed.\n",
    "\n",
    "- When using a subclass (especially one which manipulates its shape), the default ndarray.__setitem__ behaviour will call __getitem__ for basic indexing but not for advanced indexing. For such a subclass it may be preferable to call ndarray.__setitem__ with a base class ndarray view on the data. This must be done if the subclasses __getitem__ does not return views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc26a9",
   "metadata": {},
   "source": [
    "### I/O with Numpy\n",
    "- From https://numpy.org/doc/stable/user/basics.io.genfromtxt.html\n",
    "#### Importing data with genfromtxt\n",
    "- NumPy provides several functions to create arrays from tabular data. We focus here on the genfromtxt function.\n",
    "\n",
    "- In a nutshell, genfromtxt runs two main loops. The first loop converts each line of the file in a sequence of strings. The second loop converts each string to the appropriate data type. This mechanism is slower than a single loop, but gives more flexibility. In particular, genfromtxt is able to take missing data into account, when other faster and simpler functions like loadtxt cannot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3e6a1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94474e",
   "metadata": {},
   "source": [
    "#### Defining the input\n",
    "- The only mandatory argument of genfromtxt is the source of the data. It can be a string, a list of strings, a generator or an open file-like object with a read method, for example, a file or io.StringIO object. If a single string is provided, it is assumed to be the name of a local or remote file. If a list of strings or a generator returning strings is provided, each string is treated as one line in a file. When the URL of a remote file is passed, the file is automatically downloaded to the current directory and opened.\n",
    "\n",
    "- Recognized file types are text files and archives. Currently, the function recognizes gzip and bz2 (bzip2) archives. The type of the archive is determined from the extension of the file: if the filename ends with '.gz', a gzip archive is expected; if it ends with 'bz2', a bzip2 archive is assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9bea4a",
   "metadata": {},
   "source": [
    "#### Splitting the lines into columns\n",
    "#### The delimiter argument\n",
    "- Once the file is defined and open for reading, genfromtxt splits each non-empty line into a sequence of strings. Empty or commented lines are just skipped. The delimiter keyword is used to define how the splitting should take place.\n",
    "\n",
    "- Quite often, a single character marks the separation between columns. For example, comma-separated files (CSV) use a comma (,) or a semicolon (;) as delimiter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb1f4ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1, 2, 3\\n4, 5, 6\"\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7be27",
   "metadata": {},
   "source": [
    "- Another common separator is \"\\t\", the tabulation character. However, we are not limited to a single character, any string will do. By default, genfromtxt assumes delimiter=None, meaning that the line is split along white spaces (including tabs) and that consecutive white spaces are considered as a single white space.\n",
    "\n",
    "- Alternatively, we may be dealing with a fixed-width file, where columns are defined as a given number of characters. In that case, we need to set delimiter to a single integer (if all the columns have the same size) or to a sequence of integers (if columns can have different sizes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "672de9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.],\n",
       "       [  4.,   5.,  67.],\n",
       "       [890., 123.,   4.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"  1  2  3\\n 4  5 67\\n890123 4\"\n",
    "np.genfromtxt(StringIO(data), delimiter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "413a2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1234.,  567.,   89.],\n",
       "       [  nan,    4.,    7.],\n",
       "       [  nan,  456.,    7.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"123456789\\n    4   7 9\\n    4567 9\"\n",
    "np.genfromtxt(StringIO(data), delimiter=(4, 3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4892edb",
   "metadata": {},
   "source": [
    "#### The autostrip argument\n",
    "- By default, when a line is decomposed into a series of strings, the individual entries are not stripped of leading nor trailing white spaces. This behavior can be overwritten by setting the optional argument autostrip to a value of True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52bc0838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', ' abc ', ' 2'],\n",
       "       ['3', ' xxx', ' 4']], dtype='<U5')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1, abc  , 2\\n 3, xxx, 4\"\n",
    "# Without autostrip\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a8ddddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'abc', '2'],\n",
       "       ['3', 'xxx', '4']], dtype='<U5')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With autostrip\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\", autostrip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753ec41",
   "metadata": {},
   "source": [
    "#### The comments argument\n",
    "- The optional argument comments is used to define a character string that marks the beginning of a comment. By default, genfromtxt assumes comments='#'. The comment marker may occur anywhere on the line. Any character present after the comment marker(s) is simply ignored:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1e324f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.],\n",
       "       [5., 6.],\n",
       "       [7., 8.],\n",
       "       [9., 0.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"\"\"#\n",
    "# Skip me !\n",
    "# Skip me too !\n",
    "1, 2\n",
    "3, 4\n",
    "5, 6 #This is the third line of the data\n",
    "7, 8\n",
    "# And here comes the last line\n",
    "9, 0\n",
    "\"\"\"\n",
    "np.genfromtxt(StringIO(data), comments=\"#\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd04c3f",
   "metadata": {},
   "source": [
    "#### Note: There is one notable exception to this behavior: if the optional argument names=True, the first commented line will be examined for names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9c80c",
   "metadata": {},
   "source": [
    "#### Skipping lines and choosing columns\n",
    "#### The skip_header and skip_footer arguments\n",
    "- The presence of a header in the file can hinder data processing. In that case, we need to use the skip_header optional argument. The values of this argument must be an integer which corresponds to the number of lines to skip at the beginning of the file, before any other action is performed. Similarly, we can skip the last n lines of the file by using the skip_footer attribute and giving it a value of n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a709b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"\\n\".join(str(i) for i in range(10))\n",
    "np.genfromtxt(StringIO(data),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1220ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.genfromtxt(StringIO(data), skip_header=3, skip_footer=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615ce16",
   "metadata": {},
   "source": [
    "- By default, skip_header=0 and skip_footer=0, meaning that no lines are skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112569aa",
   "metadata": {},
   "source": [
    "#### The usecols argument\n",
    "- In some cases, we are not interested in all the columns of the data but only a few of them. We can select which columns to import with the usecols argument. This argument accepts a single integer or a sequence of integers corresponding to the indices of the columns to import. Remember that by convention, the first column has an index of 0. Negative integers behave the same as regular Python negative indexes.\n",
    "\n",
    "- For example, if we want to import only the first and the last columns, we can use usecols=(0, -1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2abdb6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3.],\n",
       "       [4., 6.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1 2 3\\n4 5 6\"\n",
    "np.genfromtxt(StringIO(data), usecols=(0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc2a88",
   "metadata": {},
   "source": [
    "- If the columns have names, we can also select which columns to import by giving their name to the usecols argument, either as a sequence of strings or a comma-separated string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5264bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 3.), (4., 6.)], dtype=[('a', '<f8'), ('c', '<f8')])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1 2 3 \\n4 5 6\"\n",
    "np.genfromtxt(StringIO(data), names=\"a, b, c\", usecols=(\"a\", \"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1285a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 3.), (4., 6.)], dtype=[('a', '<f8'), ('c', '<f8')])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.genfromtxt(StringIO(data), names=\"a, b, c\", usecols=(\"a, c\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fccab",
   "metadata": {},
   "source": [
    "#### Choosing the data type\n",
    "- The main way to control how the sequences of strings we have read from the file are converted to other types is to set the dtype argument. Acceptable values for this argument are:\n",
    "\n",
    "    - a single type, such as dtype=float. The output will be 2D with the given dtype, unless a name has been associated with each column with the use of the names argument (see below). Note that dtype=float is the default for genfromtxt.\n",
    "    - a sequence of types, such as dtype=(int, float, float).\n",
    "    - a comma-separated string, such as dtype=\"i4,f8,|U3\".\n",
    "    - a dictionary with two keys 'names' and 'formats'.\n",
    "    - a sequence of tuples (name, type), such as dtype=[('A', int), ('B', float)].\n",
    "    - an existing numpy.dtype object.\n",
    "    - the special value None. In that case, the type of the columns will be determined from the data itself (see below).\n",
    "\n",
    "- In all the cases but the first one, the output will be a 1D array with a structured dtype. This dtype has as many fields as items in the sequence. The field names are defined with the names keyword.\n",
    "\n",
    "- When dtype=None, the type of each column is determined iteratively from its data. We start by checking whether a string can be converted to a boolean (that is, if the string matches true or false in lower cases); then whether it can be converted to an integer, then to a float, then to a complex and eventually to a string.\n",
    "\n",
    "- The option dtype=None is provided for convenience. However, it is significantly slower than setting the dtype explicitly.\n",
    "\n",
    "#### Setting the names\n",
    "#### The names argument\n",
    "- A natural approach when dealing with tabular data is to allocate a name to each column. A first possibility is to use an explicit structured dtype, as mentioned previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "acae287d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(-1, -1, 3), ( 4,  5, 6)],\n",
       "      dtype=[('a', '<i8'), ('b', '<i8'), ('c', '<i8')])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1, 2, 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, dtype=[(_, int) for _ in \"abc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa44a4",
   "metadata": {},
   "source": [
    "- Another simpler possibility is to use the names keyword with a sequence of strings or a comma-separted string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3334cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 2., 3.), (4., 5., 6.)],\n",
       "      dtype=[('A', '<f8'), ('B', '<f8'), ('C', '<f8')])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1 2 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, names=\"A, B, C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5648e3",
   "metadata": {},
   "source": [
    "- In the example above, we used the fact that by default, dtype=float. By giving a sequence of names, we are forcing the output to a structured dtype.\n",
    "\n",
    "- We may sometimes need to define the column names from the data itself. In that case, we must use the names keyword with a value of True. The names will then be read from the first line (after the skip_header ones), even if the line is commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06192c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 2., 3.), (4., 5., 6.)],\n",
       "      dtype=[('a', '<f8'), ('b', '<f8'), ('c', '<f8')])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"So it goes\\n#a b c\\n1 2 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, skip_header=1, names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72978377",
   "metadata": {},
   "source": [
    "- The default value of names is None. If we give any other value to the keyword, the new names will overwrite the field names we may have defined with the dtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f33bfa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2., 3), (4, 5., 6)],\n",
       "      dtype=[('A', '<i8'), ('B', '<f8'), ('C', '<i8')])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1 2 3\\n 4 5 6\")\n",
    "ndtype=[('a',int), ('b', float), ('c', int)]\n",
    "names = [\"A\", \"B\", \"C\"]\n",
    "np.genfromtxt(data, names=names, dtype=ndtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70414dc",
   "metadata": {},
   "source": [
    "#### The defaultfmt argument\n",
    "- If names=None but a structured dtype is expected, names are defined with the standard NumPy default of \"f%i\", yielding names like f0, f1 and so forth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22e6db8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2., 3), (4, 5., 6)],\n",
       "      dtype=[('f0', '<i8'), ('f1', '<f8'), ('f2', '<i8')])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1 2 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, dtype=(int, float, int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9fe4a",
   "metadata": {},
   "source": [
    "- In the same way, if we don’t give enough names to match the length of the dtype, the missing names will be defined with this default template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "66fa053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2., 3), (4, 5., 6)],\n",
       "      dtype=[('a', '<i8'), ('f0', '<f8'), ('f1', '<i8')])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1 2 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, dtype=(int, float, int), names=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fcb4e",
   "metadata": {},
   "source": [
    "- We can overwrite this default with the defaultfmt argument, that takes any format string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbc6e251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2., 3), (4, 5., 6)],\n",
       "      dtype=[('var_00', '<i8'), ('var_01', '<f8'), ('var_02', '<i8')])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = StringIO(\"1 2 3\\n 4 5 6\")\n",
    "np.genfromtxt(data, dtype=(int, float, int), defaultfmt=\"var_%02i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171313d",
   "metadata": {},
   "source": [
    "#### Note: We need to keep in mind that defaultfmt is used only if some names are expected but not defined.\n",
    "\n",
    "#### Validating names\n",
    "- NumPy arrays with a structured dtype can also be viewed as recarray, where a field can be accessed as if it were an attribute. For that reason, we may need to make sure that the field name doesn’t contain any space or invalid character, or that it does not correspond to the name of a standard attribute (like size or shape), which would confuse the interpreter. genfromtxt accepts three optional arguments that provide a finer control on the names:\n",
    "\n",
    "    - deletechars\n",
    "        - Gives a string combining all the characters that must be deleted from the name. By default, invalid characters are ~!@#$%^&*()-=+~\\|]}[{';: /?.>,<.\n",
    "    - excludelist\n",
    "        - Gives a list of the names to exclude, such as return, file, print… If one of the input name is part of this list, an underscore character ('_') will be appended to it.\n",
    "    - case_sensitive\n",
    "        - Whether the names should be case-sensitive (case_sensitive=True), converted to upper case (case_sensitive=False or case_sensitive='upper') or to lower case (case_sensitive='lower').\n",
    "#### Tweaking the conversion\n",
    "#### The converters argument\n",
    "- Usually, defining a dtype is sufficient to define how the sequence of strings must be converted. However, some additional control may sometimes be required. For example, we may want to make sure that a date in a format YYYY/MM/DD is converted to a datetime object, or that a string like xx% is properly converted to a float between 0 and 1. In such cases, we should define conversion functions with the converters arguments.\n",
    "\n",
    "- The value of this argument is typically a dictionary with column indices or column names as keys and a conversion functions as values. These conversion functions can either be actual functions or lambda functions. In any case, they should accept only a string as input and output only a single element of the wanted type.\n",
    "\n",
    "- In the following example, the second column is converted from as string representing a percentage to a float between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1b072d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., nan, 45.), (6., nan,  0.)],\n",
       "      dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertfunc = lambda x: float(x.strip(\"%\"))/100.\n",
    "data = \"1, 2.3%, 45.\\n6, 78.9%, 0\"\n",
    "names = (\"i\", \"p\", \"n\")\n",
    "# General case .....\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\", names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2bf49",
   "metadata": {},
   "source": [
    "- We need to keep in mind that by default, dtype=float. A float is therefore expected for the second column. However, the strings ' 2.3%' and ' 78.9%' cannot be converted to float and we end up having np.nan instead. Let’s now use a converter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d159be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 0.023, 45.), (6., 0.789,  0.)],\n",
       "      dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converted case ...\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n",
    "              converters={1: convertfunc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b616f24",
   "metadata": {},
   "source": [
    "- The same results can be obtained by using the name of the second column (\"p\") as key instead of its index (1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b979a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1., 0.023, 45.), (6., 0.789,  0.)],\n",
       "      dtype=[('i', '<f8'), ('p', '<f8'), ('n', '<f8')])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a name for the converter ...\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n",
    "              converters={\"p\": convertfunc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49602c54",
   "metadata": {},
   "source": [
    "- Converters can also be used to provide a default for missing entries. In the following example, the converter convert transforms a stripped string into the corresponding float or into -999 if the string is empty. We need to explicitly strip the string from white spaces as it is not done by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "04e02d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1., -999.,    3.],\n",
       "       [   4.,    5.,    6.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"1, , 3\\n 4, 5, 6\"\n",
    "convert = lambda x: float(x.strip() or -999)\n",
    "np.genfromtxt(StringIO(data), delimiter=\",\",\n",
    "              converters={1: convert})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fc801",
   "metadata": {},
   "source": [
    "#### Using missing and filling values\n",
    "- Some entries may be missing in the dataset we are trying to import. In a previous example, we used a converter to transform an empty string into a float. However, user-defined converters may rapidly become cumbersome to manage.\n",
    "\n",
    "- The genfromtxt function provides two other complementary mechanisms: the missing_values argument is used to recognize missing data and a second argument, filling_values, is used to process these missing data.\n",
    "\n",
    "#### missing_values\n",
    "- By default, any empty string is marked as missing. We can also consider more complex strings, such as \"N/A\" or \"???\" to represent missing or invalid data. The missing_values argument accepts three kinds of values:\n",
    "\n",
    "- a string or a comma-separated string\n",
    "    - This string will be used as the marker for missing data for all the columns\n",
    "\n",
    "- a sequence of strings\n",
    "    - In that case, each item is associated to a column, in order.\n",
    "\n",
    "- a dictionary\n",
    "    - Values of the dictionary are strings or sequence of strings. The corresponding keys can be column indices (integers) or column names (strings). In addition, the special key None can be used to define a default applicable to all columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb59221b",
   "metadata": {},
   "source": [
    "#### filling_values\n",
    "- We know how to recognize missing data, but we still need to provide a value for these missing entries. By default, this value is determined from the expected dtype according to this table:\n",
    "\n",
    "| Expected type | Default |\n",
    "| ---- | ---- |\n",
    "| bool | False |\n",
    "| int | -1 |\n",
    "| float | np.nan |\n",
    "| complex | np.nan+0j |\n",
    "| string | '???' |\n",
    "\n",
    "- We can get a finer control on the conversion of missing values with the filling_values optional argument. Like missing_values, this argument accepts different kind of values:\n",
    "\n",
    "- a single value\n",
    "    - This will be the default for all columns\n",
    "\n",
    "- a sequence of values\n",
    "    - Each entry will be the default for the corresponding column\n",
    "\n",
    "- a dictionary\n",
    "    - Each key can be a column index or a column name, and the corresponding value should be a single object. We can use the special key None to define a default for all columns.\n",
    "\n",
    "- In the following example, we suppose that the missing values are flagged with \"N/A\" in the first column and by \"???\" in the third column. We wish to transform these missing values to 0 if they occur in the first and second column, and to -999 if they occur in the last column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe371809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 2,    3), (4, 0, -999)],\n",
       "      dtype=[('a', '<i8'), ('b', '<i8'), ('c', '<i8')])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"N/A, 2, 3\\n4, ,???\"\n",
    "kwargs = dict(delimiter=\",\",\n",
    "              dtype=int,\n",
    "              names=\"a,b,c\",\n",
    "              missing_values={0:\"N/A\", 'b':\" \", 2:\"???\"},\n",
    "              filling_values={0:0, 'b':0, 2:-999})\n",
    "np.genfromtxt(StringIO(data), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad38da",
   "metadata": {},
   "source": [
    "#### usemask\n",
    "- We may also want to keep track of the occurrence of missing data by constructing a boolean mask, with True entries where data was missing and False otherwise. To do that, we just have to set the optional argument usemask to True (the default is False). The output array will then be a MaskedArray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0fdd51",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "- From https://numpy.org/doc/stable/user/basics.types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276ac31",
   "metadata": {},
   "source": [
    "#### Array types and conversions between types\n",
    "- NumPy supports a much greater variety of numerical types than Python does. This section shows which are available, and how to modify an array’s data-type.\n",
    "- NumPy numerical types are instances of numpy.dtype (data-type) objects, each having unique characteristics. Once you have imported NumPy using import numpy as np you can create arrays with a specified dtype using the scalar types in the numpy top-level API, e.g. numpy.bool, numpy.float32, etc.\n",
    "- These scalar types as arguments to the dtype keyword that many numpy functions or methods accept. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "54e20a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=uint8)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.arange(3, dtype=np.uint8)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ca8fd",
   "metadata": {},
   "source": [
    "- Array types can also be referred to by character codes, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f0563db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3], dtype=\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "387a7e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3], dtype=\"d\").dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba13057",
   "metadata": {},
   "source": [
    "- See Specifying and constructing data types for more information about specifying and constructing data type objects, including how to specify parameters like the byte order.\n",
    "\n",
    "- To convert the type of an array, use the .astype() method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d3b94ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f7958",
   "metadata": {},
   "source": [
    "- Note that, above, we could have used the Python float object as a dtype instead of **numpy.float64**. NumPy knows that **int** refers to **numpy.int_**, **bool** means **numpy.bool**, that **float** is **numpy.float64** and **complex** is **numpy.complex128**. The other data-types do not have Python equivalents.\n",
    "\n",
    "- To determine the type of an array, look at the dtype attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7abe289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d494d8f",
   "metadata": {},
   "source": [
    "- dtype objects also contain information about the type, such as its bit-width and its byte-order. The data type can also be used indirectly to query properties of the type, such as whether it is an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36929b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.dtype(np.int64)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f326780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.issubdtype(d, np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b9bdef62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.issubdtype(d, np.floating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eacff3",
   "metadata": {},
   "source": [
    "#### Numerical Data Types\n",
    "- There are 5 basic numerical types representing booleans (bool), integers (int), unsigned integers (uint) floating point (float) and complex. A basic numerical type name combined with a numeric bitsize defines a concrete type. The bitsize is the number of bits that are needed to represent a single value in memory. For example, numpy.float64 is a 64 bit floating point data type. Some types, such as numpy.int_ and numpy.intp, have differing bitsizes, dependent on the platforms (e.g. 32-bit vs. 64-bit CPU architectures). This should be taken into account when interfacing with low-level code (such as C or Fortran) where the raw memory is addressed.\n",
    "\n",
    "### Data Types for Strings and Bytes\n",
    "- In addition to numerical types, NumPy also supports storing unicode strings, via the numpy.str_ dtype (U character code), null-terminated byte sequences via numpy.bytes_ (S character code), and arbitrary byte sequences, via numpy.void (V character code).\n",
    "\n",
    "- All of the above are fixed-width data types. They are parameterized by a width, in either bytes or unicode points, that a single data element in the array must fit inside. This means that storing an array of byte sequences or strings using this dtype requires knowing or calculating the sizes of the longest text or byte sequence in advance.\n",
    "\n",
    "- As an example, we can create an array storing the words \"hello\" and \"world!\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5aca1c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world!'], dtype='<U6')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", \"world!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffa963",
   "metadata": {},
   "source": [
    "- Here the data type is detected as a unicode string that is a maximum of 6 code points long, enough to store both entries without truncation. If we specify a shorter or longer data type, the string is either truncated or zero-padded to fit in the specified width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f3dc2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world'], dtype='<U5')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", \"world!\"], dtype=\"U5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "81233ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world!'], dtype='<U7')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", \"world!\"], dtype=\"U7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90d722a",
   "metadata": {},
   "source": [
    "- We can see the zero-padding a little more clearly if we use the bytes data type and ask NumPy to print out the bytes in the array buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "961da9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello\\x00\\x00world\\x00\\x00'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", \"world\"], dtype=\"S7\").tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa792c",
   "metadata": {},
   "source": [
    "- Each entry is padded with two extra null bytes. Note however that NumPy cannot tell the difference between intentionally stored trailing nulls and padding nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b7ea2571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [b\"hello\\0\\0\", b\"world\"]\n",
    "a = np.array(x, dtype=\"S7\")\n",
    "print(a[0])\n",
    "a[0] == x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13082c0",
   "metadata": {},
   "source": [
    "#### Relationship Between NumPy Data Types and C Data Types\n",
    "- NumPy provides both bit sized type names and names based on the names of C types. Since the definition of C types are platform dependent, this means the explicitly bit sized should be preferred to avoid platform-dependent behavior in programs using NumPy.\n",
    "\n",
    "- To ease integration with C code, where it is more natural to refer to platform-dependent C types, NumPy also provides type aliases that correspond to the C types for the platform. Some dtypes have trailing underscore to avoid confusion with builtin python type names, such as numpy.bool_.\n",
    "\n",
    "| Canonical Python API name | Python API “C-like” name | Actual C type |Description |\n",
    "| -------------------------- | ---------------------| -------------- | ------------ |\n",
    "| numpy.bool or numpy.bool_ | N/A | bool (defined in stdbool.h) |Boolean (True or False) stored as a byte. |\n",
    "| numpy.int8 |  numpy.byte | signed char | Platform-defined integer type with 8 bits. |\n",
    "| numpy.uint8 | numpy.ubyte | unsigned char | Platform-defined integer type with 8 bits without sign. |\n",
    "| numpy.int16 | numpy.short | short | Platform-defined integer type with 16 bits. |\n",
    "| numpy.uint16 | numpy.ushort | unsigned short | Platform-defined integer type with 16 bits without sign. |\n",
    "| numpy.int32 | numpy.intc | int | Platform-defined integer type with 32 bits. |\n",
    "| numpy.uint32 | numpy.uintc | unsigned int | Platform-defined integer type with 32 bits without sign. |\n",
    "| numpy.intp | N/A | ssize_t/Py_ssize_t | Platform-defined integer of size size_t; used e.g. for sizes. |\n",
    "| numpy.uintp | N/A | size_t | Platform-defined integer type capable of storing the maximum allocation size. |\n",
    "| N/A | 'p' | intptr_t | Guaranteed to hold pointers. Character code only (Python and C). |\n",
    "| N/A | 'P' | uintptr_t | Guaranteed to hold pointers. Character code only (Python and C). |\n",
    "| numpy.int32 or numpy.int64 | numpy.long | long |Platform-defined integer type with at least 32 bits. |\n",
    "| numpy.uint32 or numpy.uint64 | numpy.ulong | unsigned long | Platform-defined integer type with at least 32 bits without sign. |\n",
    "| N/A | numpy.longlong | long long | Platform-defined integer type with at least 64 bits. |\n",
    "| N/A | numpy.ulonglong | unsigned long long | Platform-defined integer type with at least 64 bits without sign. |\n",
    "| numpy.float16 | numpy.half | N/A | Half precision float: sign bit, 5 bits exponent, 10 bits mantissa. |\n",
    "| numpy.float32 | numpy.single | float | Platform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa. |\n",
    "| numpy.float64 | numpy.double | double | Platform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa.| \n",
    "| numpy.float96 or numpy.float128 | numpy.longdouble | long double | Platform-defined extended-precision float. |\n",
    "| numpy.complex64 | numpy.csingle | float complex |  Complex number, represented by two single-precision floats (real and imaginary components). | \n",
    "| numpy.complex128 | numpy.cdouble | double complex | Complex number, represented by two double-precision floats (real and imaginary components). |\n",
    "| numpy.complex192 or numpy.complex256 | numpy.clongdouble | long double complex | Complex number, represented by two extended-precision floats (real and imaginary components). |\n",
    "\n",
    "- Since many of these have platform-dependent definitions, a set of fixed-size aliases are provided\n",
    "\n",
    "#### Array scalars\n",
    "- NumPy generally returns elements of arrays as array scalars (a scalar with an associated dtype). Array scalars differ from Python scalars, but for the most part they can be used interchangeably (the primary exception is for versions of Python older than v2.x, where integer array scalars cannot act as indices for lists and tuples). There are some exceptions, such as when code requires very specific attributes of a scalar or when it checks specifically whether a value is a Python scalar. Generally, problems are easily fixed by explicitly converting array scalars to Python scalars, using the corresponding Python type function (e.g., int, float, complex, str).\n",
    "\n",
    "- The primary advantage of using array scalars is that they preserve the array type (Python may not have a matching scalar type available, e.g. int16). Therefore, the use of array scalars ensures identical behaviour between arrays and scalars, irrespective of whether the value is inside an array or not. NumPy scalars also have many of the same methods arrays do.\n",
    "\n",
    "#### Overflow errors\n",
    "- The fixed size of NumPy numeric types may cause overflow errors when a value requires more memory than available in the data type. For example, numpy.power evaluates 100 ** 9 correctly for 64-bit integers, but gives -1486618624 (incorrect) for a 32-bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "18e1ec0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1000000000000000000)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(100, 9, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cfc4cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(-1486618624)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(100, 9, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3bf27",
   "metadata": {},
   "source": [
    "- The behaviour of NumPy and Python integer types differs significantly for integer overflows and may confuse users expecting NumPy integers to behave similar to Python’s int. Unlike NumPy, the size of Python’s int is flexible. This means Python integers may expand to accommodate any integer and will not overflow.\n",
    "\n",
    "- NumPy provides numpy.iinfo and numpy.finfo to verify the minimum or maximum values of NumPy integer and floating point values respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c217972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for int64\n",
      "---------------------------------------------------------------\n",
      "min = -9223372036854775808\n",
      "max = 9223372036854775807\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for int32\n",
      "---------------------------------------------------------------\n",
      "min = -2147483648\n",
      "max = 2147483647\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for int64\n",
      "---------------------------------------------------------------\n",
      "min = -9223372036854775808\n",
      "max = 9223372036854775807\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.iinfo(int)) # Bounds of the default integer on this system.\n",
    "print(np.iinfo(np.int32)) # Bounds of a 32-bit integer\n",
    "print(np.iinfo(np.int64)) # Bounds of a 64-bit integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa444062",
   "metadata": {},
   "source": [
    "- If 64-bit integers are still too small the result may be cast to a floating point number. Floating point numbers offer a larger, but inexact, range of possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f6f5c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1e+200\n",
      "Machine parameters for float64\n",
      "---------------------------------------------------------------\n",
      "precision =  15   resolution = 1.0000000000000001e-15\n",
      "machep =    -52   eps =        2.2204460492503131e-16\n",
      "negep =     -53   epsneg =     1.1102230246251565e-16\n",
      "minexp =  -1022   tiny =       2.2250738585072014e-308\n",
      "maxexp =   1024   max =        1.7976931348623157e+308\n",
      "nexp =       11   min =        -max\n",
      "smallest_normal = 2.2250738585072014e-308   smallest_subnormal = 4.9406564584124654e-324\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(np.power(100, 100, dtype=np.int64)) # Incorrect even with 64-bit int\n",
    "print(np.power(100, 100, dtype=np.float64)) # Floating point is bigger than int64\n",
    "print(np.finfo(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef8a15e",
   "metadata": {},
   "source": [
    "#### Floating point precision\n",
    "- Many functions in NumPy, especially those in numpy.linalg, involve floating-point arithmetic, which can introduce small inaccuracies due to the way computers represent decimal numbers. For instance, when performing basic arithmetic operations involving floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "33f7c6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7755575615628914e-17"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3 - .2 - .1 # This does not equal 0 due to floating-point precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94105242",
   "metadata": {},
   "source": [
    "- To handle such cases, it’s advisable to use functions like np.isclose to compare values, rather than checking for exact equality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3d28d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(0.3 - 0.2 - 0.1, 0, rtol=1e-05)  # Check for closeness to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae82d2",
   "metadata": {},
   "source": [
    "- In this example, np.isclose accounts for the minor inaccuracies that occur in floating-point calculations by applying a relative tolerance, ensuring that results within a small threshold are considered close.\n",
    "\n",
    "#### Extended precision\n",
    "- Python’s floating-point numbers are usually 64-bit floating-point numbers, nearly equivalent to numpy.float64. In some unusual situations it may be useful to use floating-point numbers with more precision. Whether this is possible in numpy depends on the hardware and on the development environment: specifically, x86 machines provide hardware floating-point with 80-bit precision, and while most C compilers provide this as their long double type, MSVC (standard for Windows builds) makes long double identical to double (64 bits). NumPy makes the compiler’s long double available as numpy.longdouble (and np.clongdouble for the complex numbers). You can find out what your numpy provides with np.finfo(np.longdouble).\n",
    "\n",
    "- NumPy does not provide a dtype with more precision than C’s long double; in particular, the 128-bit IEEE quad precision data type (FORTRAN’s REAL*16) is not available.\n",
    "\n",
    "- For efficient memory alignment, numpy.longdouble is usually stored padded with zero bits, either to 96 or 128 bits. Which is more efficient depends on hardware and development environment; typically on 32-bit systems they are padded to 96 bits, while on 64-bit systems they are typically padded to 128 bits. np.longdouble is padded to the system default; np.float96 and np.float128 are provided for users who want specific padding. In spite of the names, np.float96 and np.float128 provide only as much precision as np.longdouble, that is, 80 bits on most x86 machines and 64 bits in standard Windows builds.\n",
    "\n",
    "- Be warned that even if numpy.longdouble offers more precision than python float, it is easy to lose that extra precision, since python often forces values to pass through float. For example, the % formatting operator requires its arguments to be converted to standard python types, and it is therefore impossible to preserve extended precision even if many decimal places are requested. It can be useful to test your code with the value 1 + np.finfo(np.longdouble).eps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec45858",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "- From https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "- The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.\n",
    "- NumPy operations are usually done on pairs of arrays on an element-by-element basis. In the simplest case, the two arrays must have exactly the same shape, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03a7d0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 6.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = np.array([2.0, 2.0, 2.0])\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cccae4",
   "metadata": {},
   "source": [
    "- NumPy’s broadcasting rule relaxes this constraint when the arrays’ shapes meet certain constraints. The simplest broadcasting example occurs when an array and a scalar value are combined in an operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "663ced61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 6.])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = 2.0\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c149e4f",
   "metadata": {},
   "source": [
    "- The result is equivalent to the previous example where b was an array. We can think of the scalar b being stretched during the arithmetic operation into an array with the same shape as a. The new elements in b, as shown in Figure 1, are simply copies of the original scalar. The stretching analogy is only conceptual. NumPy is smart enough to use the original scalar value without actually making copies so that broadcasting operations are as memory and computationally efficient as possible.\n",
    "- The code in the second example is more efficient than that in the first because broadcasting moves less memory around during the multiplication (b is a scalar rather than an array).\n",
    "\n",
    "#### General broadcasting rules\n",
    "- When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimension and works its way left. Two dimensions are compatible when\n",
    "    - they are equal, or\n",
    "    - one of them is 1.\n",
    "\n",
    "- If these conditions are not met, a ValueError: operands could not be broadcast together exception is thrown, indicating that the arrays have incompatible shapes.\n",
    "- Input arrays do not need to have the same number of dimensions. The resulting array will have the same number of dimensions as the input array with the greatest number of dimensions, where the size of each dimension is the largest size of the corresponding dimension among the input arrays. Note that missing dimensions are assumed to have size one.\n",
    "- For example, if you have a 256x256x3 array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
    "```\n",
    "Image  (3d array): 256 x 256 x 3\n",
    "Scale  (1d array):             3\n",
    "Result (3d array): 256 x 256 x 3\n",
    "```\n",
    "\n",
    "- When either of the dimensions compared is one, the other is used. In other words, dimensions with size 1 are stretched or “copied” to match the other.\n",
    "- In the following example, both the A and B arrays have axes with length one that are expanded to a larger size during the broadcast operation:\n",
    "``` \n",
    "A      (4d array):  8 x 1 x 6 x 1\n",
    "B      (3d array):      7 x 1 x 5\n",
    "Result (4d array):  8 x 7 x 6 x 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e8b2b",
   "metadata": {},
   "source": [
    "#### Broadcastable arrays\n",
    "- A set of arrays is called “broadcastable” to the same shape if the above rules produce a valid result.\n",
    "- For example, if a.shape is (5,1), b.shape is (1,6), c.shape is (6,) and d.shape is () so that d is a scalar, then a, b, c, and d are all broadcastable to dimension (5,6); and\n",
    "    - a acts like a (5,6) array where a[:,0] is broadcast to the other columns,\n",
    "    - b acts like a (5,6) array where b[0,:] is broadcast to the other rows,\n",
    "    - c acts like a (1,6) array and therefore like a (5,6) array where c[:] is broadcast to every row, and finally,\n",
    "    - d acts like a (5,6) array where the single value is repeated.\n",
    "\n",
    "- Here are some more examples:\n",
    "```\n",
    "A      (2d array):  5 x 4\n",
    "B      (1d array):      1\n",
    "Result (2d array):  5 x 4\n",
    "\n",
    "A      (2d array):  5 x 4\n",
    "B      (1d array):      4\n",
    "Result (2d array):  5 x 4\n",
    "\n",
    "A      (3d array):  15 x 3 x 5\n",
    "B      (3d array):  15 x 1 x 5\n",
    "Result (3d array):  15 x 3 x 5\n",
    "\n",
    "A      (3d array):  15 x 3 x 5\n",
    "B      (2d array):       3 x 5\n",
    "Result (3d array):  15 x 3 x 5\n",
    "\n",
    "A      (3d array):  15 x 3 x 5\n",
    "B      (2d array):       3 x 1\n",
    "Result (3d array):  15 x 3 x 5\n",
    "```\n",
    "\n",
    "- Here are examples of shapes that do not broadcast:\n",
    "```\n",
    "A      (1d array):  3\n",
    "B      (1d array):  4 # trailing dimensions do not match\n",
    "\n",
    "A      (2d array):      2 x 1\n",
    "B      (3d array):  8 x 4 x 3 # second from last dimensions mismatched\n",
    "```\n",
    "- An example of broadcasting when a 1-d array is added to a 2-d array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd0a1b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [11., 12., 13.],\n",
       "       [21., 22., 23.],\n",
       "       [31., 32., 33.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[ 0.0,  0.0,  0.0],\n",
    "              [10.0, 10.0, 10.0],\n",
    "              [20.0, 20.0, 20.0],\n",
    "              [30.0, 30.0, 30.0]])\n",
    "b = np.array([1.0, 2.0, 3.0])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "44a7edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = np.array([1.0, 2.0, 3.0, 4.0])\n",
    "# a + b\n",
    "# Would cause an error\n",
    "# ValueError: operands could not be broadcast together with shapes (4,3) (4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfdd2d4",
   "metadata": {},
   "source": [
    "- Broadcasting provides a convenient way of taking the outer product (or any other outer operation) of two arrays. The following example shows an outer addition operation of two 1-d arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9ca8cbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [11., 12., 13.],\n",
       "       [21., 22., 23.],\n",
       "       [31., 32., 33.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0.0, 10.0, 20.0, 30.0])\n",
    "b = np.array([1.0, 2.0, 3.0])\n",
    "a[:, np.newaxis] + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37913be",
   "metadata": {},
   "source": [
    "- Here the newaxis index operator inserts a new axis into a, making it a two-dimensional 4x1 array. Combining the 4x1 array with b, which has shape (3,), yields a 4x3 array.\n",
    "\n",
    "#### A practical example: vector quantization\n",
    "- Broadcasting comes up quite often in real world problems. A typical example occurs in the vector quantization (VQ) algorithm used in information theory, classification, and other related areas. The basic operation in VQ finds the closest point in a set of points, called codes in VQ jargon, to a given point, called the observation. In the very simple, two-dimensional case shown below, the values in observation describe the weight and height of an athlete to be classified. The codes represent different classes of athletes. [1] Finding the closest point requires calculating the distance between observation and each of the codes. The shortest distance provides the best match. In this example, codes[0] is the closest class indicating that the athlete is likely a basketball player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d448eeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array, argmin, sqrt, sum\n",
    "observation = array([111.0, 188.0])\n",
    "codes = array([[102.0, 203.0],\n",
    "               [132.0, 193.0],\n",
    "               [45.0, 155.0],\n",
    "               [57.0, 173.0]])\n",
    "diff = codes - observation    # the broadcast happens here\n",
    "dist = sqrt(sum(diff**2,axis=-1))\n",
    "argmin(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa377c",
   "metadata": {},
   "source": [
    "- In this example, the observation array is stretched to match the shape of the codes array:\n",
    "```\n",
    "Observation      (1d array):      2\n",
    "Codes            (2d array):  4 x 2\n",
    "Diff             (2d array):  4 x 2\n",
    "```\n",
    "- The basic operation of vector quantization calculates the distance between an object to be classified, the dark square, and multiple known codes, the gray circles. In this simple case, the codes represent individual classes. More complex cases use multiple codes per class.\n",
    "- Typically, a large number of observations, perhaps read from a database, are compared to a set of codes. Consider this scenario:\n",
    "```\n",
    "Observation      (2d array):      10 x 3\n",
    "Codes            (3d array):   5 x 1 x 3\n",
    "Diff             (3d array):  5 x 10 x 3\n",
    "```\n",
    "- The three-dimensional array, diff, is a consequence of broadcasting, not a necessity for the calculation. Large data sets will generate a large intermediate array that is computationally inefficient. Instead, if each observation is calculated individually using a Python loop around the code in the two-dimensional example above, a much smaller array is used.\n",
    "\n",
    "Broadcasting is a powerful tool for writing short and usually intuitive code that does its computations very efficiently in C. However, there are cases when broadcasting uses unnecessarily large amounts of memory for a particular algorithm. In these cases, it is better to write the algorithm’s outer loop in Python. This may also produce more readable code, as algorithms that use broadcasting tend to become more difficult to interpret as the number of dimensions in the broadcast increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681b293",
   "metadata": {},
   "source": [
    "### Copies and views\n",
    "- From https://numpy.org/doc/stable/user/basics.copies.html\n",
    "- When operating on NumPy arrays, it is possible to access the internal data buffer directly using a view without copying data around. This ensures good performance but can also cause unwanted problems if the user is not aware of how this works. Hence, it is important to know the difference between these two terms and to know which operations return copies and which return views.\n",
    "\n",
    "- The NumPy array is a data structure consisting of two parts: the contiguous data buffer with the actual data elements and the metadata that contains information about the data buffer. The metadata includes data type, strides, and other important information that helps manipulate the ndarray easily. See the Internal organization of NumPy arrays section for a detailed look.\n",
    "\n",
    "#### View\n",
    "- It is possible to access the array differently by just changing certain metadata like stride and dtype without changing the data buffer. This creates a new way of looking at the data and these new arrays are called views. The data buffer remains the same, so any changes made to a view reflects in the original copy. A view can be forced through the ndarray.view method.\n",
    "\n",
    "#### Copy\n",
    "- When a new array is created by duplicating the data buffer as well as the metadata, it is called a copy. Changes made to the copy do not reflect on the original array. Making a copy is slower and memory-consuming but sometimes necessary. A copy can be forced by using ndarray.copy.\n",
    "\n",
    "#### Indexing operations\n",
    "- Views are created when elements can be addressed with offsets and strides in the original array. Hence, basic indexing always creates views. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3757475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "28532db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[1:3] # creates a view\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76614117",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1:3] = [10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7136dae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b614f0",
   "metadata": {},
   "source": [
    "- Here, y gets changed when x is changed because it is a view.\n",
    "- Advanced indexing, on the other hand, always creates copies. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abef89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9).reshape(3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3f44f42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[[1, 2]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f3a0acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.base is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38660c",
   "metadata": {},
   "source": [
    "- Here, y is a copy, as signified by the base attribute. We can also confirm this by assigning new values to x[[1, 2]] which in turn will not affect y at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "572ba460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [10, 11, 12],\n",
       "       [13, 14, 15]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[1, 2]] = [[10, 11, 12], [13, 14, 15]]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f470c274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda796b",
   "metadata": {},
   "source": [
    "- It must be noted here that during the assignment of x[[1, 2]] no view or copy is created as the assignment happens in-place.\n",
    "\n",
    "#### Other operations\n",
    "- The numpy.reshape function creates a view where possible or a copy otherwise. In most cases, the strides can be modified to reshape the array with a view. However, in some cases where the array becomes non-contiguous (perhaps after a ndarray.transpose operation), the reshaping cannot be done by modifying strides and requires a copy. In these cases, we can raise an error by assigning the new shape to the shape attribute of the array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "71b3ccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((2, 3))\n",
    "y = x.T  # makes the array non-contiguous\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "252e7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y.view()\n",
    "#  z.shape = 6 # Will raise an AttributeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc93845",
   "metadata": {},
   "source": [
    "- Taking the example of another operation, ravel returns a contiguous flattened view of the array wherever possible. On the other hand, ndarray.flatten always returns a flattened copy of the array. However, to guarantee a view in most cases, x.reshape(-1) may be preferable.\n",
    "#### How to tell if the array is a view or a copy\n",
    "- The base attribute of the ndarray makes it easy to tell if an array is a view or a copy. The base attribute of a view returns the original array while it returns None for a copy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8274d95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06c2cf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.reshape(3, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "36d114aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.base  # .reshape() creates a view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "edf6445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 7, 8],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y[[2, 1]]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "53798635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.base is None  # advanced indexing creates a copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f47b07",
   "metadata": {},
   "source": [
    "- Note that the base attribute should not be used to determine if an ndarray object is new; only if it is a view or a copy of another ndarray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c51ad",
   "metadata": {},
   "source": [
    "### Working with Arrays of Strings And Bytes\n",
    "- From https://numpy.org/doc/stable/user/basics.strings.html\n",
    "- While NumPy is primarily a numerical library, it is often convenient to work with NumPy arrays of strings or bytes. The two most common use cases are:\n",
    "    - Working with data loaded or memory-mapped from a data file, where one or more of the fields in the data is a string or bytestring, and the maximum length of the field is known ahead of time. This often is used for a name or label field.\n",
    "    - Using NumPy indexing and broadcasting with arrays of Python strings of unknown length, which may or may not have data defined for every value.\n",
    "\n",
    "- For the first use case, NumPy provides the fixed-width numpy.void, numpy.str_ and numpy.bytes_ data types. For the second use case, numpy provides numpy.dtypes.StringDType. Below we describe how to work with both fixed-width and variable-width string arrays, how to convert between the two representations, and provide some advice for most efficiently working with string data in NumPy.\n",
    "\n",
    "#### Fixed-width data types\n",
    "- Before NumPy 2.0, the fixed-width numpy.str_, numpy.bytes_, and numpy.void data types were the only types available for working with strings and bytestrings in NumPy. For this reason, they are used as the default dtype for strings and bytestrings, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "15040f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world'], dtype='<U5')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([\"hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20501f97",
   "metadata": {},
   "source": [
    "- Here the detected data type is '<U5', or little-endian unicode string data, with a maximum length of 5 unicode code points.\n",
    "- Similarly for bytestrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "276bf5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'hello', b'world'], dtype='|S5')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([b\"hello\", b\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d5c68",
   "metadata": {},
   "source": [
    "- Since this is a one-byte encoding, the byteorder is ‘|’ (not applicable), and the data type detected is a maximum 5 character bytestring.\n",
    "- You can also use numpy.void to represent bytestrings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b63015c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'\\x68\\x65\\x6C\\x6C\\x6F', b'\\x77\\x6F\\x72\\x6C\\x64'], dtype='|V5')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([b\"hello\", b\"world\"]).astype(np.void)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9931a",
   "metadata": {},
   "source": [
    "- This is most useful when working with byte streams that are not well represented as bytestrings, and instead are better thought of as collections of 8-bit integers.\n",
    "#### Variable-width strings\n",
    "- **Note**: numpy.dtypes.StringDType is a new addition to NumPy, implemented using the new support in NumPy for flexible user-defined data types and is not as extensively tested in production workflows as the older NumPy data types.\n",
    "- Often, real-world string data does not have a predictable length. In these cases it is awkward to use fixed-width strings, since storing all the data without truncation requires knowing the length of the longest string one would like to store in the array before the array is created.\n",
    "- To support situations like this, NumPy provides numpy.dtypes.StringDType, which stores variable-width string data in a UTF-8 encoding in a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18f69d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['this is a longer string', 'short string'], dtype=StringDType())"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.dtypes import StringDType\n",
    "data = [\"this is a longer string\", \"short string\"]\n",
    "arr = np.array(data, dtype=StringDType())\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edbc457",
   "metadata": {},
   "source": [
    "- Note that unlike fixed-width strings, StringDType is not parameterized by the maximum length of an array element, arbitrarily long or short strings can live in the same array without needing to reserve storage for padding bytes in the short strings.\n",
    "- Also note that unlike fixed-width strings and most other NumPy data types, StringDType does not store the string data in the “main” ndarray data buffer. Instead, the array buffer is used to store metadata about where the string data are stored in memory. This difference means that code expecting the array buffer to contain string data will not function correctly, and will need to be updated to support StringDType.\n",
    "\n",
    "#### Missing data support\n",
    "- Often string datasets are not complete, and a special label is needed to indicate that a value is missing. By default StringDType does not have any special support for missing values, besides the fact that empty strings are used to populate empty arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a15a3a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', ''], dtype=StringDType())"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(3, dtype=StringDType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35dcadc",
   "metadata": {},
   "source": [
    "- Optionally, you can pass create an instance of StringDType with support for missing values by passing na_object as a keyword argument for the initializer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e0493279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['this array has', None, 'as an entry'],\n",
       "      dtype=StringDType(na_object=None))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = StringDType(na_object=None)\n",
    "arr = np.array([\"this array has\", None, \"as an entry\"], dtype=dt)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6a61419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[1] is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c89cd",
   "metadata": {},
   "source": [
    "- The na_object can be any arbitrary python object. Common choices are numpy.nan, float('nan'), None, an object specifically intended to represent missing data like pandas.NA, or a (hopefully) unique string like \"__placeholder__\".\n",
    "\n",
    "- NumPy has special handling for NaN-like sentinels and string sentinels.\n",
    "#### NaN-like Missing Data Sentinels\n",
    "- A NaN-like sentinel returns itself as the result of arithmetic operations. This includes the python nan float and the Pandas missing data sentinel pd.NA. NaN-like sentinels inherit these behaviors in string operations. This means that, for example, the result of addition with any other string is the sentinel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d5a3b23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hellohello', nan, 'worldworld'], dtype=StringDType(na_object=nan))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = StringDType(na_object=np.nan)\n",
    "arr = np.array([\"hello\", np.nan, \"world\"], dtype=dt)\n",
    "arr + arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a89a8",
   "metadata": {},
   "source": [
    "- Following the behavior of nan in float arrays, NaN-like sentinels sort to the end of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "58850f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world', nan], dtype=StringDType(na_object=nan))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa164f3",
   "metadata": {},
   "source": [
    "#### String Missing Data Sentinels\n",
    "- A string missing data value is an instance of str or subtype of str. If such an array is passed to a string operation or a cast, “missing” entries are treated as if they have a value given by the string sentinel. Comparison operations similarly use the sentinel value directly for missing entries.\n",
    "\n",
    "#### Other Sentinels\n",
    "- Other objects, such as None are also supported as missing data sentinels. If any missing data are present in an array using such a sentinel, then string operations will raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8fa57fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = StringDType(na_object=None)\n",
    "arr = np.array([\"this array has\", None, \"as an entry\"])\n",
    "# np.sort(arr) # TypeError # cannot sort string with NoneType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ffed6",
   "metadata": {},
   "source": [
    "#### Coercing Non-strings\n",
    "- By default, non-string data are coerced to strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fbe8586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '<object object at 0x00000254C42D3C60>', '3.4'],\n",
       "      dtype=StringDType())"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, object(), 3.4], dtype=StringDType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc3ff6",
   "metadata": {},
   "source": [
    "- If this behavior is not desired, an instance of the DType can be created that disables string coercion by setting coerce=False in the initializer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7798a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([1, object(), 3.4], dtype=StringDType(coerce=False)) # dissallowed coersion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d50be5",
   "metadata": {},
   "source": [
    "- This allows strict data validation in the same pass over the data NumPy uses to create the array. Setting coerce=True recovers the default behavior allowing coercion to strings.\n",
    "#### Casting To and From Fixed-Width Strings\n",
    "- StringDType supports round-trip casts between numpy.str_, numpy.bytes_, and numpy.void. Casting to a fixed-width string is most useful when strings need to be memory-mapped in an ndarray or when a fixed-width string is needed for reading and writing to a columnar data format with a known maximum string length.\n",
    "\n",
    "- In all cases, casting to a fixed-width string requires specifying the maximum allowed string length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "52c22ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'world'], dtype='<U5')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([\"hello\", \"world\"], dtype=StringDType())\n",
    "# arr.astype(np.str_)   TypeError: Casting from StringDType to a fixed-width dtype with an unspecified size is not currently supported\n",
    "arr.astype(\"U5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b32f56",
   "metadata": {},
   "source": [
    "- The numpy.bytes_ cast is most useful for string data that is known to contain only ASCII characters, as characters outside this range cannot be represented in a single byte in the UTF-8 encoding and are rejected.\n",
    "- Any valid unicode string can be cast to numpy.str_, although since numpy.str_ uses a 32-bit UCS4 encoding for all characters, this will often waste memory for real-world textual data that can be well-represented by a more memory-efficient encoding.\n",
    "- Additionally, any valid unicode string can be cast to numpy.void, storing the UTF-8 bytes directly in the output array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9e15a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'\\x68\\x65\\x6C\\x6C\\x6F', b'\\x77\\x6F\\x72\\x6C\\x64'], dtype='|V5')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([\"hello\", \"world\"], dtype=StringDType())\n",
    "arr.astype(\"V5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0365a",
   "metadata": {},
   "source": [
    "- Care must be taken to ensure that the output array has enough space for the UTF-8 bytes in the string, since the size of a UTF-8 bytestream in bytes is not necessarily the same as the number of characters in the string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a0a93",
   "metadata": {},
   "source": [
    "### Structured arrays\n",
    "- From https://numpy.org/doc/stable/user/basics.rec.html\n",
    "#### Introduction\n",
    "- Structured arrays are ndarrays whose datatype is a composition of simpler datatypes organized as a sequence of named fields. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3d18e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Rex', 9, 81.), ('Fido', 3, 27.)],\n",
       "      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f4')])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([('Rex', 9, 81.0), ('Fido', 3, 27.0)],\n",
    "             dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d8be7",
   "metadata": {},
   "source": [
    "- Here x is a one-dimensional array of length two whose datatype is a structure with three fields: 1. A string of length 10 or less named ‘name’, 2. a 32-bit integer named ‘age’, and 3. a 32-bit float named ‘weight’.\n",
    "- If you index x at position 1 you get a structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "87242429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.void(('Fido', 3, 27.0), dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f4')])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e429422",
   "metadata": {},
   "source": [
    "You can access and modify individual fields of a structured array by indexing with the field name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b63e7f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 3], dtype=int32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6bc1c010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('Rex', 5, 81.), ('Fido', 5, 27.)],\n",
       "      dtype=[('name', '<U10'), ('age', '<i4'), ('weight', '<f4')])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['age'] = 5\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea41ff",
   "metadata": {},
   "source": [
    "- Structured datatypes are designed to be able to mimic ‘structs’ in the C language, and share a similar memory layout. They are meant for interfacing with C code and for low-level manipulation of structured buffers, for example for interpreting binary blobs. For these purposes they support specialized features such as subarrays, nested datatypes, and unions, and allow control over the memory layout of the structure.\n",
    "\n",
    "- Users looking to manipulate tabular data, such as stored in csv files, may find other pydata projects more suitable, such as xarray, pandas, or DataArray. These provide a high-level interface for tabular data analysis and are better optimized for that use. For instance, the C-struct-like memory layout of structured arrays in numpy can lead to poor cache behavior in comparison.\n",
    "\n",
    "#### Structured datatypes\n",
    "A structured datatype can be thought of as a sequence of bytes of a certain length (the structure’s itemsize) which is interpreted as a collection of fields. Each field has a name, a datatype, and a byte offset within the structure. The datatype of a field may be any numpy datatype including other structured datatypes, and it may also be a subarray data type which behaves like an ndarray of a specified shape. The offsets of the fields are arbitrary, and fields may even overlap. These offsets are usually determined automatically by numpy, but can also be specified.\n",
    "\n",
    "#### Structured datatype creation\n",
    "Structured datatypes may be created using the function numpy.dtype. There are 4 alternative forms of specification which vary in flexibility and conciseness. These are further documented in the Data Type Objects reference page, and in summary they are:\n",
    "\n",
    "1. A list of tuples, one tuple per field\n",
    "- Each tuple has the form (fieldname, datatype, shape) where shape is optional. fieldname is a string (or tuple if titles are used, see Field Titles below), datatype may be any object convertible to a datatype, and shape is a tuple of integers specifying subarray shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "51272beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('x', '<f4'), ('y', '<f4'), ('z', '<f4', (2, 2))])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype([('x', 'f4'), ('y', np.float32), ('z', 'f4', (2, 2))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac500f",
   "metadata": {},
   "source": [
    "- If fieldname is the empty string '', the field will be given a default name of the form f#, where # is the integer index of the field, counting from 0 from the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b302175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('x', '<f4'), ('f1', '<i4'), ('z', '<i8')])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype([('x', 'f4'), ('', 'i4'), ('z', 'i8')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108943d1",
   "metadata": {},
   "source": [
    "- The byte offsets of the fields within the structure and the total structure itemsize are determined automatically.\n",
    "\n",
    "2. A string of comma-separated dtype specifications\n",
    "\n",
    "- In this shorthand notation any of the string dtype specifications may be used in a string and separated by commas. The itemsize and byte offsets of the fields are determined automatically, and the field names are given the default names f0, f1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2fa7cac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', '<i8'), ('f1', '<f4'), ('f2', 'S3')])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype('i8, f4, S3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "42d49dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', 'i1', (3,)), ('f1', '<f4'), ('f2', '<f8', (2, 3))])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype('3int8, float32, (2, 3)float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1738ca5",
   "metadata": {},
   "source": [
    "3. A dictionary of field parameter arrays\n",
    "\n",
    "- This is the most flexible form of specification since it allows control over the byte-offsets of the fields and the itemsize of the structure.\n",
    "\n",
    "- The dictionary has two required keys, ‘names’ and ‘formats’, and four optional keys, ‘offsets’, ‘itemsize’, ‘aligned’ and ‘titles’. The values for ‘names’ and ‘formats’ should respectively be a list of field names and a list of dtype specifications, of the same length. The optional ‘offsets’ value should be a list of integer byte-offsets, one for each field within the structure. If ‘offsets’ is not given the offsets are determined automatically. The optional ‘itemsize’ value should be an integer describing the total size in bytes of the dtype, which must be large enough to contain all the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8167b7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('col1', '<i4'), ('col2', '<f4')])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype({'names': ['col1', 'col2'], 'formats': ['i4', 'f4']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "17dcb3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype({'names': ['col1', 'col2'], 'formats': ['<i4', '<f4'], 'offsets': [0, 4], 'itemsize': 12})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype({'names': ['col1', 'col2'],\n",
    "          'formats': ['i4', 'f4'],\n",
    "          'offsets': [0, 4],\n",
    "          'itemsize': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95b33a",
   "metadata": {},
   "source": [
    "- Offsets may be chosen such that the fields overlap, though this will mean that assigning to one field may clobber any overlapping field’s data. As an exception, fields of numpy.object_ type cannot overlap with other fields, because of the risk of clobbering the internal object pointer and then dereferencing it.\n",
    "- The optional ‘aligned’ value can be set to True to make the automatic offset computation use aligned offsets (see Automatic byte offsets and alignment), as if the ‘align’ keyword argument of numpy.dtype had been set to True.\n",
    "- The optional ‘titles’ value should be a list of titles of the same length as ‘names’, see Field Titles below.\n",
    "\n",
    "4. A dictionary of field names\n",
    "- The keys of the dictionary are the field names and the values are tuples specifying type and offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "023c024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('col1', 'i1'), ('col2', '<f4')])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype({\"col1\": (\"i1\", 0), \"col2\": (\"f4\", 1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2129821",
   "metadata": {},
   "source": [
    "- This form was discouraged because Python dictionaries did not preserve order in Python versions before Python 3.6. Field Titles may be specified by using a 3-tuple, see below.\n",
    "\n",
    "#### Manipulating and displaying structured datatypes\n",
    "- The list of field names of a structured datatype can be found in the names attribute of the dtype object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b2faea9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x', 'y')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.dtype([(\"x\", \"i8\"), (\"y\", \"f4\")])\n",
    "d.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f256aba",
   "metadata": {},
   "source": [
    "- The dtype of each individual field can be looked up by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a43a1af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7059175",
   "metadata": {},
   "source": [
    "- The field names may be modified by assigning to the names attribute using a sequence of strings of the same length.\n",
    "- The dtype object also has a dictionary-like attribute, fields, whose keys are the field names (and Field Titles, see below) and whose values are tuples containg the dtype and byte offset or each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bb9ca292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'x': (dtype('int64'), 0), 'y': (dtype('float32'), 8)})"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af5f28",
   "metadata": {},
   "source": [
    "- Both the names and fields attributes will equal None for unstructured arrays. The recommended way to test if a dtype is structured is with if dt.names is not None rather than if dt.names, to account for dtypes with 0 fields.\n",
    "- The string representation of a structured datatype is shown in the “list of tuples” form if possible, otherwise numpy falls back to using the more general dictionary form.\n",
    "\n",
    "#### Automatic byte offsets and alignment\n",
    "- Numpy uses one of two methods to automatically determine the field byte offsets and the overall itemsize of a structured datatype, depending on whether align=True was specified as a keyword argument to numpy.dtype.\n",
    "- By default (align=False), numpy will pack the fields together such that each field starts at the byte offset the previous field ended, and the fields are contiguous in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "62246490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets: [0, 1, 2, 6, 7, 15]\n",
      "itemsize: 17\n"
     ]
    }
   ],
   "source": [
    "def print_offsets(d):\n",
    "    print(\"offsets:\", [d.fields[name][1] for name in d.names])\n",
    "    print(\"itemsize:\", d.itemsize)\n",
    "\n",
    "print_offsets(np.dtype(\"u1, u1, i4, u1, i8, u2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3bb05",
   "metadata": {},
   "source": [
    "- If align=True is set, numpy will pad the structure in the same way many C compilers would pad a C-struct. Aligned structures can give a performance improvement in some cases, at the cost of increased datatype size. Padding bytes are inserted between fields such that each field’s byte offset will be a multiple of that field’s alignment, which is usually equal to the field’s size in bytes for simple datatypes, see PyArray_Descr.alignment. The structure will also have trailing padding added so that its itemsize is a multiple of the largest field’s alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f84082de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offsets: [0, 1, 4, 8, 16, 24]\n",
      "itemsize: 32\n"
     ]
    }
   ],
   "source": [
    "print_offsets(np.dtype('u1, u1, i4, u1, i8, u2', align=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56874d",
   "metadata": {},
   "source": [
    "- Note that although almost all modern C compilers pad in this way by default, padding in C structs is C-implementation-dependent so this memory layout is not guaranteed to exactly match that of a corresponding struct in a C program. Some work may be needed, either on the numpy side or the C side, to obtain exact correspondence.\n",
    "- If offsets were specified using the optional offsets key in the dictionary-based dtype specification, setting align=True will check that each field’s offset is a multiple of its size and that the itemsize is a multiple of the largest field size, and raise an exception if not.\n",
    "- If the offsets of the fields and itemsize of a structured array satisfy the alignment conditions, the array will have the ALIGNED flag set.\n",
    "- A convenience function numpy.lib.recfunctions.repack_fields converts an aligned dtype or array to a packed one and vice versa. It takes either a dtype or structured ndarray as an argument, and returns a copy with fields re-packed, with or without padding bytes.\n",
    "\n",
    "#### Field titles\n",
    "- In addition to field names, fields may also have an associated title, an alternate name, which is sometimes used as an additional description or alias for the field. The title may be used to index an array, just like a field name.\n",
    "- To add titles when using the list-of-tuples form of dtype specification, the field name may be specified as a tuple of two strings instead of a single string, which will be the field’s title and field name respectively. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "33dcaee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([(('my title', 'name'), '<f4')])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype([(('my title', 'name'), 'f4')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e3132",
   "metadata": {},
   "source": [
    "- When using the first form of dictionary-based specification, the titles may be supplied as an extra 'titles' key as described above. When using the second (discouraged) dictionary-based specification, the title can be supplied by providing a 3-element tuple (datatype, offset, title) instead of the usual 2-element tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f5b1b0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([(('my title', 'name'), '<i4')])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype({'name': ('i4', 0, 'my title')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6581f",
   "metadata": {},
   "source": [
    "- The dtype.fields dictionary will contain titles as keys, if any titles are used. This means effectively that a field with a title will be represented twice in the fields dictionary. The tuple values for these fields will also have a third element, the field title. Because of this, and because the names attribute preserves the field order while the fields attribute may not, it is recommended to iterate through the fields of a dtype using the names attribute of the dtype, which will not list titles, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f6870761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dtype('int64'), 0)\n",
      "(dtype('float32'), 8)\n"
     ]
    }
   ],
   "source": [
    "for name in d.names:\n",
    "    print(d.fields[name][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807671d",
   "metadata": {},
   "source": [
    "#### Union types\n",
    "- Structured datatypes are implemented in numpy to have base type numpy.void by default, but it is possible to interpret other numpy types as structured types using the (base_dtype, dtype) form of dtype specification described in Data Type Objects. Here, base_dtype is the desired underlying dtype, and fields and flags will be copied from dtype. This dtype is similar to a ‘union’ in C.\n",
    "\n",
    "### Indexing and assignment to structured arrays\n",
    "#### Assigning data to a structured array\n",
    "- There are a number of ways to assign values to a structured array: Using python tuples, using scalar values, or using other structured arrays.\n",
    "\n",
    "#### Assignment from Python Native Types (Tuples)\n",
    "- The simplest way to assign values to a structured array is using python tuples. Each assigned value should be a tuple of length equal to the number of fields in the array, and not a list or array as these will trigger numpy’s broadcasting rules. The tuple’s elements are assigned to the successive fields of the array, from left to right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "41208ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 2., 3.), (7, 8., 9.)],\n",
       "      dtype=[('f0', '<i8'), ('f1', '<f4'), ('f2', '<f8')])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([(1, 2, 3), (4, 5, 6)], dtype='i8, f4, f8')\n",
    "x[1] = (7, 8, 9)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2a9830",
   "metadata": {},
   "source": [
    "#### Assignment from Scalars\n",
    "- A scalar assigned to a structured element will be assigned to all fields. This happens when a scalar is assigned to a structured array, or when an unstructured array is assigned to a structured array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bf246400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(3, 3.,  True, b'3'), (3, 3.,  True, b'3')],\n",
       "      dtype=[('f0', '<i8'), ('f1', '<f4'), ('f2', '?'), ('f3', 'S1')])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros(2, dtype='i8, f4, ?, S1')\n",
    "x[:] = 3\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f019e46",
   "metadata": {},
   "source": [
    "- Structured arrays can also be assigned to unstructured arrays, but only if the structured datatype has just a single field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c26d6d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "twofield = np.zeros(2, dtype=[('A', 'i4'), ('B', 'i4')])\n",
    "onefield = np.zeros(2, dtype=[('A', 'i4')])\n",
    "nostruct = np.zeros(2, dtype='i4')\n",
    "# nostruct[:] = twofield # TypeError: Cannot cast array data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9148efc3",
   "metadata": {},
   "source": [
    "#### Assignment from other Structured Arrays\n",
    "- Assignment between two structured arrays occurs as if the source elements had been converted to tuples and then assigned to the destination elements. That is, the first field of the source array is assigned to the first field of the destination array, and the second field likewise, and so on, regardless of field names. Structured arrays with a different number of fields cannot be assigned to each other. Bytes of the destination structure which are not included in any of the fields are unaffected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e4136375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0., b'0.0', b''), (0., b'0.0', b''), (0., b'0.0', b'')],\n",
       "      dtype=[('x', '<f4'), ('y', 'S3'), ('z', 'O')])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(3, dtype=[('a', 'i8'), ('b', 'f4'), ('c', 'S3')])\n",
    "b = np.ones(3, dtype=[('x', 'f4'), ('y', 'S3'), ('z', 'O')])\n",
    "b[:] = a\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04bc9a",
   "metadata": {},
   "source": [
    "#### Assignment involving subarrays\n",
    "- When assigning to fields which are subarrays, the assigned value will first be broadcast to the shape of the subarray.\n",
    "\n",
    "### Indexing structured arrays\n",
    "#### Accessing Individual Fields\n",
    "- Individual fields of a structured array may be accessed and modified by indexing the array with the field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "424e5a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\n",
    "x['foo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c3afd373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(10, 2.), (10, 4.)], dtype=[('foo', '<i8'), ('bar', '<f4')])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['foo'] = 10\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c99b2d",
   "metadata": {},
   "source": [
    "- The resulting array is a view into the original array. It shares the same memory locations and writing to the view will modify the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "981c5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(10, 11.), (10, 11.)], dtype=[('foo', '<i8'), ('bar', '<f4')])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x['bar']\n",
    "y[:] = 11\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27eeb6",
   "metadata": {},
   "source": [
    "- This view has the same dtype and itemsize as the indexed field, so it is typically a non-structured array, except in the case of nested structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "234b01ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), (2,), (12,))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype, y.shape, y.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660dd4a1",
   "metadata": {},
   "source": [
    "- If the accessed field is a subarray, the dimensions of the subarray are appended to the shape of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c92ac355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\n",
    "x['a'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ee32407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3, 3)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"b\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1610d",
   "metadata": {},
   "source": [
    "#### Accessing Multiple Fields\n",
    "- One can index and assign to a structured array with a multi-field index, where the index is a list of field names.\n",
    "- The result of indexing with a multi-field index is a view into the original array, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5e6119c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0.), (0, 0.), (0, 0.)],\n",
       "      dtype={'names': ['a', 'c'], 'formats': ['<i4', '<f4'], 'offsets': [0, 8], 'itemsize': 12})"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(3, dtype=[('a', 'i4'), ('b', 'i4'), ('c', 'f4')])\n",
    "a[['a', 'c']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57549286",
   "metadata": {},
   "source": [
    "- Assignment to the view modifies the original array. The view’s fields will be in the order they were indexed. Note that unlike for single-field indexing, the dtype of the view has the same itemsize as the original array, and has fields at the same offsets as in the original array, and unindexed fields are merely missing.\n",
    "- Assignment to an array with a multi-field index modifies the original array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e3afae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(2, 0, 3.), (2, 0, 3.), (2, 0, 3.)],\n",
       "      dtype=[('a', '<i4'), ('b', '<i4'), ('c', '<f4')])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[['a', 'c']] = (2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6927fab",
   "metadata": {},
   "source": [
    "- This obeys the structured array assignment rules described above. For example, this means that one can swap the values of two fields using appropriate multi-field indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1023448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['a', 'c']] = a[['c', 'a']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f6262a",
   "metadata": {},
   "source": [
    "#### Indexing with an Integer to get a Structured Scalar\n",
    "- Indexing a single element of a structured array (with an integer index) returns a structured scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "24cea9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.void((1, 2.0, 3.0), dtype=[('f0', '<i4'), ('f1', '<f4'), ('f2', '<f4')])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([(1, 2., 3.)], dtype='i, f, f')\n",
    "scalar = x[0]\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3cdf849d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.void"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726bbba",
   "metadata": {},
   "source": [
    "- Unlike other numpy scalars, structured scalars are mutable and act like views into the original array, such that modifying the scalar will modify the original array. Structured scalars also support access and assignment by field name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b290dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(1, 100.), (3,   4.)], dtype=[('foo', '<i8'), ('bar', '<f4')])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\n",
    "s = x[0]\n",
    "s['bar'] = 100\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a017d",
   "metadata": {},
   "source": [
    "- Similarly to tuples, structured scalars can also be indexed with an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "30c9e623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = np.array([(1, 2., 3.)], dtype='i, f, f')[0]\n",
    "scalar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fcd5bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar[1] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3da212",
   "metadata": {},
   "source": [
    "- Thus, tuples might be thought of as the native Python equivalent to numpy’s structured types, much like native python integers are the equivalent to numpy’s integer types. Structured scalars may be converted to a tuple by calling numpy.ndarray.item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "feee0391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4.0, 3.0), tuple)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item(), type(scalar.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3bf07",
   "metadata": {},
   "source": [
    "#### Viewing structured arrays containing objects\n",
    "- In order to prevent clobbering object pointers in fields of object type, numpy currently does not allow views of structured arrays containing objects.\n",
    "\n",
    "#### Structure comparison and promotion\n",
    "- If the dtypes of two void structured arrays are equal, testing the equality of the arrays will result in a boolean array with the dimensions of the original arrays, with elements set to True where all fields of the corresponding structures are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "545bc642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])\n",
    "b = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])\n",
    "a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ece02",
   "metadata": {},
   "source": [
    "- NumPy will promote individual field datatypes to perform the comparison. So the following is also valid (note the 'f4' dtype for the 'a' field):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0c9fc3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([(1.0, 1), (2.5, 2)], dtype=[(\"a\", \"f4\"), (\"b\", \"i4\")])\n",
    "a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02509eb7",
   "metadata": {},
   "source": [
    "- To compare two structured arrays, it must be possible to promote them to a common dtype as returned by numpy.result_type and numpy.promote_types. This enforces that the number of fields, the field names, and the field titles must match precisely. When promotion is not possible, for example due to mismatching field names, NumPy will raise an error. Promotion between two structured dtypes results in a canonical dtype that ensures native byte-order for all fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "de296c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', '<i4'), ('f1', '<i4')])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(np.dtype(\"i,>i\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4e0b9ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', '<i4'), ('f1', '<i4')])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(np.dtype(\"i,>i\"), np.dtype(\"i,i\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67d9b8",
   "metadata": {},
   "source": [
    "- The resulting dtype from promotion is also guaranteed to be packed, meaning that all fields are ordered contiguously and any unnecessary padding is removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6d41f892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype({'names': ['f0', 'f2'], 'formats': ['i1', '<i4'], 'offsets': [0, 4], 'itemsize': 9})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = np.dtype(\"i1,V3,i4,V1\")[[\"f0\", \"f2\"]]\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9d9c01c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', 'i1'), ('f2', '<i4')])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8486a",
   "metadata": {},
   "source": [
    "- Note that the result prints without offsets or itemsize indicating no additional padding. If a structured dtype is created with align=True ensuring that dtype.isalignedstruct is true, this property is preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "dfabcc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype({'names': ['f0', 'f2'], 'formats': ['i1', '<i4'], 'offsets': [0, 4], 'itemsize': 12}, align=True)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = np.dtype(\"i1,V3,i4,V1\", align=True)[[\"f0\", \"f2\"]]\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "6debbb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', 'i1'), ('f2', '<i4')], align=True)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "567af2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(dt).isalignedstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2c9cd",
   "metadata": {},
   "source": [
    "- When promoting multiple dtypes, the result is aligned if any of the inputs is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0a83b3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', '<i4'), ('f1', '<i4')], align=True)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.result_type(np.dtype(\"i,i\"), np.dtype(\"i,i\", align=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b53e54",
   "metadata": {},
   "source": [
    "- The < and > operators always return False when comparing void structured arrays, and arithmetic and bitwise operations are not supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1a033",
   "metadata": {},
   "source": [
    "#### Record arrays\n",
    "- As an optional convenience numpy provides an ndarray subclass, numpy.recarray that allows access to fields of structured arrays by attribute instead of only by index. Record arrays use a special datatype, numpy.record, that allows field access by attribute on the structured scalars obtained from the array. The numpy.rec module provides functions for creating recarrays from various objects. Additional helper functions for creating and manipulating structured arrays can be found in numpy.lib.recfunctions.\n",
    "\n",
    "- The simplest way to create a record array is with numpy.rec.array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "31db8b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr = np.rec.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n",
    "                   dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'S10')])\n",
    "recordarr.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "69af830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(1, 2., b'Hello'), (2, 3., b'World')],\n",
       "          dtype=[('foo', '<i4'), ('bar', '<f4'), ('baz', 'S10')])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d461cd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(2, 3., b'World')],\n",
       "          dtype=[('foo', '<i4'), ('bar', '<f4'), ('baz', 'S10')])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "32df043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr[1:2].foo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3355e",
   "metadata": {},
   "source": [
    "- numpy.rec.array can convert a wide variety of arguments into record arrays, including structured arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4b0db32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n",
    "            dtype=[('foo', 'i4'), ('bar', 'f4'), ('baz', 'S10')])\n",
    "recordarr = np.rec.array(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da13b8",
   "metadata": {},
   "source": [
    "- The numpy.rec module provides a number of other convenience functions for creating record arrays, see record array creation routines.\n",
    "- A record array representation of a structured array can be obtained using the appropriate view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "be28c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n",
    "               dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'S10')])\n",
    "recordarr = arr.view(dtype=np.dtype((np.record, arr.dtype)),\n",
    "                     type=np.recarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c81784",
   "metadata": {},
   "source": [
    "- For convenience, viewing an ndarray as type numpy.recarray will automatically convert to numpy.record datatype, so the dtype can be left out of the view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a40c7bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype((numpy.record, [('foo', '<i4'), ('bar', '<f4'), ('baz', 'S10')]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr = arr.view(np.recarray)\n",
    "recordarr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f6407",
   "metadata": {},
   "source": [
    "- To get back to a plain ndarray both the dtype and type must be reset. The following view does so, taking into account the unusual case that the recordarr was not a structured type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "862cb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = recordarr.view(recordarr.dtype.fields or recordarr.dtype, np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eae07a",
   "metadata": {},
   "source": [
    "- Record array fields accessed by index or by attribute are returned as a record array if the field has a structured type but as a plain ndarray otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c5432f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordarr = np.rec.array([('Hello', (1, 2)), (\"World\", (3, 4))],\n",
    "                dtype=[('foo', 'S6'),('bar', [('A', int), ('B', int)])])\n",
    "type(recordarr.foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2ebbaf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.rec.recarray"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recordarr.bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e936f0",
   "metadata": {},
   "source": [
    "- **Note**: that if a field has the same name as an ndarray attribute, the ndarray attribute takes precedence. Such fields will be inaccessible by attribute but will still be accessible by index.\n",
    "#### NOTE: END OF STRUCTED ARRAYS: the page continue to list record array helper functions in an API reference format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e79b78",
   "metadata": {},
   "source": [
    "### Universal functions (ufunc) basics\n",
    "- From https://numpy.org/doc/stable/user/basics.ufuncs.html\n",
    "- A universal function (or ufunc for short) is a function that operates on ndarrays in an element-by-element fashion, supporting array broadcasting, type casting, and several other standard features. That is, a ufunc is a “vectorized” wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs.\n",
    "- In NumPy, universal functions are instances of the numpy.ufunc class. Many of the built-in functions are implemented in compiled C code. The basic ufuncs operate on scalars, but there is also a generalized kind for which the basic elements are sub-arrays (vectors, matrices, etc.), and broadcasting is done over other dimensions. The simplest example is the addition operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c0e717e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 6])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,2,3,4]) + np.array([1,1,-1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5188fe97",
   "metadata": {},
   "source": [
    "- One can also produce custom numpy.ufunc instances using the numpy.frompyfunc factory function.\n",
    "#### Ufunc methods\n",
    "- All ufuncs have four methods. They can be found at Methods. However, these methods only make sense on scalar ufuncs that take two input arguments and return one output argument. Attempting to call these methods on other ufuncs will cause a ValueError.\n",
    "\n",
    "- The reduce-like methods all take an axis keyword, a dtype keyword, and an out keyword, and the arrays must all have dimension >= 1. The axis keyword specifies the axis of the array over which the reduction will take place (with negative values counting backwards). Generally, it is an integer, though for numpy.ufunc.reduce, it can also be a tuple of int to reduce over several axes at once, or None, to reduce over all axes. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "53f869b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9).reshape(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "603ab5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 12, 21])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add.reduce(x, 1) # essentially the sum method, but faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8622f459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(10)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add.reduce(np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "24efd9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(36)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add.reduce(x, (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ceedd",
   "metadata": {},
   "source": [
    "- The dtype keyword allows you to manage a very common problem that arises when naively using ufunc.reduce. Sometimes you may have an array of a certain data type and wish to add up all of its elements, but the result does not fit into the data type of the array. This commonly happens if you have an array of single-byte integers. The dtype keyword allows you to alter the data type over which the reduction takes place (and therefore the type of the output). Thus, you can ensure that the output is a data type with precision large enough to handle your output. The responsibility of altering the reduce type is mostly up to you. There is one exception: if no dtype is given for a reduction on the “add” or “multiply” operations, then if the input type is an integer (or Boolean) data-type and smaller than the size of the numpy.int_ data type, it will be internally upcast to the int_ (or numpy.uint) data-type. In the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f1035274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f025bc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 28., 80.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply.reduce(x, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df27d9d9",
   "metadata": {},
   "source": [
    "- Finally, the out keyword allows you to provide an output array (or a tuple of output arrays for multi-output ufuncs). If out is given, the dtype argument is only used for the internal computations. Considering x from the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0c2b8cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros(3, dtype=int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a2eb6cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 28, 80])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply.reduce(x, dtype=float, out=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436723e",
   "metadata": {},
   "source": [
    "- Ufuncs also have a fifth method, numpy.ufunc.at, that allows in place operations to be performed using advanced indexing. No buffering is used on the dimensions where advanced indexing is used, so the advanced index can list an item more than once and the operation will be performed on the result of the previous operation for that item.\n",
    "\n",
    "#### Output type determination\n",
    "- If the input arguments of the ufunc (or its methods) are ndarrays, then the output will be as well. The exception is when the result is zero-dimensional, in which case the output will be converted to an array scalar. This can be avoided by passing in out=... or out=Ellipsis.\n",
    "\n",
    "- If some or all of the input arguments are not ndarrays, then the output may not be an ndarray either. Indeed, if any input defines an __array_ufunc__ method, control will be passed completely to that function, i.e., the ufunc is overridden.\n",
    "\n",
    "I- f none of the inputs overrides the ufunc, then all output arrays will be passed to the __array_wrap__ method of the input (besides ndarrays, and scalars) that defines it and has the highest __array_priority__ of any other input to the universal function. The default __array_priority__ of the ndarray is 0.0, and the default __array_priority__ of a subtype is 0.0. Matrices have __array_priority__ equal to 10.0.\n",
    "\n",
    "- All ufuncs can also take output arguments which must be arrays or subclasses. If necessary, the result will be cast to the data-type(s) of the provided output array(s). If the output has an __array_wrap__ method it is called instead of the one found on the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2037700",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "- Each universal function takes array inputs and produces array outputs by performing the core function element-wise on the inputs (where an element is generally a scalar, but can be a vector or higher-order sub-array for generalized ufuncs). Standard broadcasting rules are applied so that inputs not sharing exactly the same shapes can still be usefully operated on.\n",
    "- By these rules, if an input has a dimension size of 1 in its shape, the first data entry in that dimension will be used for all calculations along that dimension. In other words, the stepping machinery of the ufunc will simply not step along that dimension (the stride will be 0 for that dimension).\n",
    "\n",
    "#### Type casting rules\n",
    "- **Note**: In NumPy 1.6.0, a type promotion API was created to encapsulate the mechanism for determining output types. See the functions numpy.result_type, numpy.promote_types, and numpy.min_scalar_type for more details.\n",
    "- At the core of every ufunc is a one-dimensional strided loop that implements the actual function for a specific type combination. When a ufunc is created, it is given a static list of inner loops and a corresponding list of type signatures over which the ufunc operates. The ufunc machinery uses this list to determine which inner loop to use for a particular case. You can inspect the .types attribute for a particular ufunc to see which type combinations have a defined inner loop and which output type they produce (character codes are used in said output for brevity).\n",
    "- Casting must be done on one or more of the inputs whenever the ufunc does not have a core loop implementation for the input types provided. If an implementation for the input types cannot be found, then the algorithm searches for an implementation with a type signature to which all of the inputs can be cast “safely.” The first one it finds in its internal list of loops is selected and performed, after all necessary type casting. Recall that internal copies during ufuncs (even for casting) are limited to the size of an internal buffer (which is user settable).\n",
    "- **Note**: Universal functions in NumPy are flexible enough to have mixed type signatures. Thus, for example, a universal function could be defined that works with floating-point and integer values. See numpy.ldexp for an example.\n",
    "- By the above description, the casting rules are essentially implemented by the question of when a data type can be cast “safely” to another data type. The answer to this question can be determined in Python with a function call: can_cast(fromtype, totype). The example below shows the results of this call for the 24 internally supported types on the author’s 64-bit system. You can generate this table for your system with the code given in the example.\n",
    "#### Example\n",
    "- Code segment showing the \"can cast safely\" table for a 64-bit system. Generally the output depends on the system; your system might result in a different table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "377e7eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ? b h i l q n p B H I L Q N P e f d g F D G S U V O M m\n",
      "? Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\n",
      "b - Y Y Y Y Y Y Y - - - - - - - Y Y Y Y Y Y Y Y Y Y Y - Y\n",
      "h - - Y Y Y Y Y Y - - - - - - - - Y Y Y Y Y Y Y Y Y Y - Y\n",
      "i - - - Y Y Y Y Y - - - - - - - - - Y Y - Y Y Y Y Y Y - Y\n",
      "l - - - Y Y Y Y Y - - - - - - - - - Y Y - Y Y Y Y Y Y - Y\n",
      "q - - - - - Y Y Y - - - - - - - - - Y Y - Y Y Y Y Y Y - Y\n",
      "n - - - - - Y Y Y - - - - - - - - - Y Y - Y Y Y Y Y Y - Y\n",
      "p - - - - - Y Y Y - - - - - - - - - Y Y - Y Y Y Y Y Y - Y\n",
      "B - - Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\n",
      "H - - - Y Y Y Y Y - Y Y Y Y Y Y - Y Y Y Y Y Y Y Y Y Y - Y\n",
      "I - - - - - Y Y Y - - Y Y Y Y Y - - Y Y - Y Y Y Y Y Y - Y\n",
      "L - - - - - Y Y Y - - Y Y Y Y Y - - Y Y - Y Y Y Y Y Y - Y\n",
      "Q - - - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\n",
      "N - - - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\n",
      "P - - - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\n",
      "e - - - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y Y - -\n",
      "f - - - - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y - -\n",
      "d - - - - - - - - - - - - - - - - - Y Y - Y Y Y Y Y Y - -\n",
      "g - - - - - - - - - - - - - - - - - Y Y - Y Y Y Y Y Y - -\n",
      "F - - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y Y - -\n",
      "D - - - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y - -\n",
      "G - - - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y - -\n",
      "S - - - - - - - - - - - - - - - - - - - - - - Y Y Y Y - -\n",
      "U - - - - - - - - - - - - - - - - - - - - - - - Y Y Y - -\n",
      "V - - - - - - - - - - - - - - - - - - - - - - - - Y Y - -\n",
      "O - - - - - - - - - - - - - - - - - - - - - - - - - Y - -\n",
      "M - - - - - - - - - - - - - - - - - - - - - - - - Y Y Y -\n",
      "m - - - - - - - - - - - - - - - - - - - - - - - - Y Y - Y\n"
     ]
    }
   ],
   "source": [
    "mark = {False: ' -', True: ' Y'}\n",
    "def print_table(ntypes):\n",
    "    print('X ' + ' '.join(ntypes))\n",
    "    for row in ntypes:\n",
    "        print(row, end='')\n",
    "        for col in ntypes:\n",
    "            print(mark[np.can_cast(row, col)], end='')\n",
    "        print()\n",
    "\n",
    "print_table(np.typecodes['All'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d9caa",
   "metadata": {},
   "source": [
    "- You should note that, while included in the table for completeness, the ‘S’, ‘U’, and ‘V’ types cannot be operated on by ufuncs. Also, note that on a 32-bit system the integer types may have different sizes, resulting in a slightly altered table.\n",
    "- Mixed scalar-array operations use a different set of casting rules that ensure that a scalar cannot “upcast” an array unless the scalar is of a fundamentally different kind of data (i.e., under a different hierarchy in the data-type hierarchy) than the array. This rule enables you to use scalar constants in your code (which, as Python types, are interpreted accordingly in ufuncs) without worrying about whether the precision of the scalar constant will cause upcasting on your large (small precision) array.\n",
    "\n",
    "#### Use of internal buffers\n",
    "- Internally, buffers are used for misaligned data, swapped data, and data that has to be converted from one data type to another. The size of internal buffers is settable on a per-thread basis. There can be up to \n",
    " buffers of the specified size created to handle the data from all the inputs and outputs of a ufunc. The default size of a buffer is 10,000 elements. Whenever buffer-based calculation would be needed, but all input arrays are smaller than the buffer size, those misbehaved or incorrectly-typed arrays will be copied before the calculation proceeds. Adjusting the size of the buffer may therefore alter the speed at which ufunc calculations of various sorts are completed. A simple interface for setting this variable is accessible using the function numpy.setbufsize.\n",
    "\n",
    " #### Error handling\n",
    "- Universal functions can trip special floating-point status registers in your hardware (such as divide-by-zero). If available on your platform, these registers will be regularly checked during calculation. Error handling is controlled on a per-thread basis, and can be configured using the functions numpy.seterr and numpy.seterrcall.\n",
    "#### Overriding ufunc behavior\n",
    "- Classes (including ndarray subclasses) can override how ufuncs act on them by defining certain special methods. For details, see Standard array subclasses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
